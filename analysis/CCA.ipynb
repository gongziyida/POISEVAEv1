{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eb0457c-26d9-4df7-8fec-5fc8d29d4ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.distributions import Laplace\n",
    "import poisevae\n",
    "from poisevae.datasets import CUB\n",
    "from poisevae.utils import NN_lookup, Categorical, sent_emb\n",
    "from poisevae.networks.CUBNetworks import EncImg, DecImg, EncTxt, DecTxt\n",
    "\n",
    "from scipy.linalg import eig\n",
    "from sklearn.cross_decomposition import CCA\n",
    "\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 20\n",
    "plt.rcParams['font.weight'] = 'normal'\n",
    "plt.rcParams['mathtext.fontset'] = 'cm'\n",
    "plt.rcParams['text.usetex'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fffd3d4-3bd4-4ad6-a7ed-07190f013e63",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Declarations & Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4873bbb-ba73-44a7-9dfa-a142edbbf974",
   "metadata": {},
   "outputs": [],
   "source": [
    "device ='cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68205657-3d7e-4628-bc1a-1d2d0f90bb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_PATH = os.path.expanduser('~')\n",
    "DATA_PATH = os.path.join(HOME_PATH, 'Datasets/CUB/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "492f04ea-cff7-4527-a677-2809e4f96683",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SIZE = 81920\n",
    "true_img = torch.load('../../true_data_img.pt')[:DATA_SIZE]\n",
    "true_txt = torch.load('../../true_data_txt.pt')[:DATA_SIZE]\n",
    "true_img_pca = torch.load('../../true_data_img_pca.pt')[:DATA_SIZE].to('cpu', torch.float32)#.numpy()\n",
    "true_sent_emb = torch.load('../../true_data_sent_embedding.pt')[:DATA_SIZE].to('cpu', torch.float32)#.numpy()\n",
    "sent_PC = torch.load('../../sentence_emb_PC.pt').to(device, torch.float32)\n",
    "img_PC = torch.load('../../image_PC.pt').to(device, torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aafea47f-af65-4dc2-9341-38bbf8f3f811",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_PATH, 'cub/oc:3_msl:32/cub.emb'), 'rb') as file:\n",
    "    emb = pickle.load(file)\n",
    "with open(os.path.join(DATA_PATH, 'cub/oc:3_msl:32/cub.weights'), 'rb') as file:\n",
    "    weights = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e1e5b9c-bb34-479b-991c-dc456452f6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_transform(X, PC):\n",
    "    li = X.split(2048, 0)\n",
    "    return torch.cat([e - torch.matmul(PC, e.unsqueeze(-1)).squeeze() for e in li])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "108f69df-afac-4da0-bdc6-8c55266c9cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_corr(imgs, txts, true_img_mean, true_txt_mean):\n",
    "    if isinstance(imgs, np.ndarray):\n",
    "        imgs = torch.from_numpy(imgs)\n",
    "    if isinstance(txts, np.ndarray):\n",
    "        txts = torch.from_numpy(txts)\n",
    "    if isinstance(true_img_mean, np.ndarray):\n",
    "        true_img_mean = torch.from_numpy(true_img_mean)\n",
    "    if isinstance(true_txt_mean, np.ndarray):\n",
    "        true_txt_mean = torch.from_numpy(true_txt_mean)\n",
    "    # Assume all are projected\n",
    "    corr = F.cosine_similarity((imgs.cpu() - true_img_mean.cpu()), \n",
    "                               (txts.cpu() - true_txt_mean.cpu())).mean()\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05c12880-864b-4f32-9159-c47fa9d94315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_cca(gen_img=None, gen_txt_emb=None):\n",
    "    if gen_img is not None:\n",
    "        gen_img = torch.cat(gen_img).to(device, torch.float32)\n",
    "        gen_img = pca_transform(gen_img, img_PC.to(device, torch.float32)).cpu().numpy()\n",
    "    else:\n",
    "        gen_img = true_img_pca\n",
    "        \n",
    "    if gen_txt_emb is not None: \n",
    "        gen_txt_emb = torch.from_numpy(np.vstack(gen_txt_emb)).to(device, torch.float32)\n",
    "        gen_txt_emb = pca_transform(gen_txt_emb, sent_PC.to(device, torch.float32)).cpu().numpy()\n",
    "    else:\n",
    "        gen_txt_emb = true_sent_emb\n",
    "    \n",
    "    gen_img_cca, gen_sent_cca = cca.transform(gen_img, gen_txt_emb)\n",
    "    # gen_img_cca, gen_sent_cca = gen_img @ im_proj.cpu().numpy(), gen_txt_emb @ emb_proj.cpu().numpy()\n",
    "    return float(calculate_corr(gen_img_cca, gen_sent_cca, true_img_cca_mean, true_sent_cca_mean))\n",
    "\n",
    "def eval_model(vae):\n",
    "    corr = []\n",
    "    for mode in ('joint', 'i2s', 's2i'):\n",
    "        gen_txt_emb = []\n",
    "        gen_img = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(len(true_img)):\n",
    "                if mode == 'i2s':\n",
    "                    results = vae([true_img[i], None], n_gibbs_iter=50)\n",
    "                    gen_txt_i = results['x_rec'][1].probs.argmax(dim=1).reshape(true_img[i].shape[0], -1)\n",
    "                    gen_txt_emb.append(np.zeros((true_img[i].shape[0], emb.shape[1])))\n",
    "                    sent_emb(gen_txt_i.cpu().numpy().astype(np.int32), emb, weights, gen_txt_emb[-1])\n",
    "                elif mode == 's2i':\n",
    "                    results = vae([None, true_txt[i]], n_gibbs_iter=50)\n",
    "                    gen_img.append(results['x_rec'][0].loc)\n",
    "                elif mode == 'joint':\n",
    "                    results = vae.generate(true_img[i].shape[0], n_gibbs_iter=50)\n",
    "                    gen_img.append(results['x_rec'][0].loc)\n",
    "                    gen_txt_i = results['x_rec'][1].probs.argmax(dim=1).reshape(true_img[i].shape[0], -1)\n",
    "                    gen_txt_emb.append(np.zeros((true_img[i].shape[0], emb.shape[1])))\n",
    "                    sent_emb(gen_txt_i.cpu().numpy().astype(np.int32), emb, weights, gen_txt_emb[-1])\n",
    "                else: \n",
    "                    raise ValueError\n",
    "\n",
    "            if mode == 'i2s':\n",
    "                corr.append(('i2s', perform_cca(gen_txt_emb=gen_txt_emb)))\n",
    "            elif mode == 's2i':\n",
    "                corr.append(('s2i', perform_cca(gen_img=gen_img)))\n",
    "            elif mode == 'joint':\n",
    "                corr.append(('joint', perform_cca(gen_img=gen_img, gen_txt_emb=gen_txt_emb)))\n",
    "            else: \n",
    "                raise ValueError \n",
    "        del results, gen_img, gen_txt_emb # Free memory\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ebc4e09-8805-4c00-a3de-bb1193d276a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cca(views, k=None, eps=1e-12):\n",
    "    \"\"\"Compute (multi-view) CCA\n",
    "    Args:\n",
    "        views (list): list of views where each view `v_i` is of size `N x o_i`\n",
    "        k (int): joint projection dimension | if None, find using Otsu\n",
    "        eps (float): regulariser [default: 1e-12]\n",
    "    Returns:\n",
    "        correlations: correlations along each of the k dimensions\n",
    "        projections: projection matrices for each view\n",
    "    \"\"\"\n",
    "    V = len(views)  # number of views\n",
    "    N = views[0].size(0)  # number of observations (same across views)\n",
    "    os = [v.size(1) for v in views]\n",
    "    kmax = np.min(os)\n",
    "    ocum = np.cumsum([0] + os)\n",
    "    os_sum = sum(os)\n",
    "    A, B = np.zeros([os_sum, os_sum]), np.zeros([os_sum, os_sum])\n",
    "\n",
    "    for i in range(V):\n",
    "        v_i = views[i]\n",
    "        v_i_bar = v_i - v_i.mean(0).expand_as(v_i)  # centered, N x o_i\n",
    "        C_ij = (1.0 / (N - 1)) * torch.mm(v_i_bar.t(), v_i_bar)\n",
    "        # A[ocum[i]:ocum[i + 1], ocum[i]:ocum[i + 1]] = C_ij\n",
    "        B[ocum[i]:ocum[i + 1], ocum[i]:ocum[i + 1]] = C_ij\n",
    "        for j in range(i + 1, V):\n",
    "            v_j = views[j]  # N x o_j\n",
    "            v_j_bar = v_j - v_j.mean(0).expand_as(v_j)  # centered\n",
    "            C_ij = (1.0 / (N - 1)) * torch.mm(v_i_bar.t(), v_j_bar)\n",
    "            A[ocum[i]:ocum[i + 1], ocum[j]:ocum[j + 1]] = C_ij\n",
    "            A[ocum[j]:ocum[j + 1], ocum[i]:ocum[i + 1]] = C_ij.t()\n",
    "\n",
    "    A[np.diag_indices_from(A)] += eps\n",
    "    B[np.diag_indices_from(B)] += eps\n",
    "\n",
    "    eigenvalues, eigenvectors = eig(A, B)\n",
    "    # TODO: sanity check to see that all eigenvalues are e+0i\n",
    "    idx = eigenvalues.argsort()[::-1]  # sort descending\n",
    "    eigenvalues = eigenvalues[idx]  # arrange in descending order\n",
    "\n",
    "    if k is None:\n",
    "        t = threshold(eigenvalues.real[:kmax])\n",
    "        k = np.abs(np.asarray(eigenvalues.real[0::10]) - t).argmin() * 10  # closest k % 10 == 0 idx\n",
    "        print('k unspecified, (auto-)choosing:', k)\n",
    "\n",
    "    eigenvalues = eigenvalues[idx[:k]]\n",
    "    eigenvectors = eigenvectors[:, idx[:k]]\n",
    "\n",
    "    correlations = torch.from_numpy(eigenvalues.real).type_as(views[0])\n",
    "    proj_matrices = torch.split(torch.from_numpy(eigenvectors.real).type_as(views[0]), os)\n",
    "\n",
    "    return correlations, proj_matrices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c169391a-70e8-432d-a2c3-cbf53297f5e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## CCA over truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ade1f9e-0308-4f2a-8684-393933256b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('CCA_model.pkl', 'rb') as f:\n",
    "        cca = pickle.load(f)\n",
    "except FileNotFoundError:\n",
    "    cca = CCA(n_components=10, tol=1e-8)\n",
    "    cca.fit(true_img_pca, true_sent_emb)\n",
    "    with open('CCA_model.pkl','wb') as f:\n",
    "        pickle.dump(cca, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a7be008-33f6-489c-aa77-efd1360abac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4774, dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_img_cca, true_sent_cca = cca.transform(true_img_pca, true_sent_emb)\n",
    "# corr, (im_proj, emb_proj) = cca([true_img_pca, true_sent_emb], k=40)\n",
    "true_img_cca_mean, true_sent_cca_mean = true_img_cca.mean(axis=0), true_sent_cca.mean(axis=0)\n",
    "calculate_corr(true_img_cca, true_sent_cca, true_img_cca_mean, true_sent_cca_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c6fef6d-01fd-4e87-8d35-9192e2ddb538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_img_cca, true_sent_cca = true_img_pca @ im_proj, true_sent_emb @ emb_proj\n",
    "# true_img_cca_mean, true_sent_cca_mean = true_img_cca.mean(axis=0), true_sent_cca.mean(axis=0)\n",
    "# calculate_corr(true_img_cca, true_sent_cca, true_img_cca_mean, true_sent_cca_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a16a867-05f2-4666-8a06-2812b34ca78a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Check on convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd940e42-e849-490c-b189-d5929a6a8ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4742, dtype=torch.float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.arange(true_img_pca.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "true_img_cca_hat, true_sent_cca_hat = cca.transform(true_img_pca[idx], true_sent_emb[idx])\n",
    "# true_img_cca_hat, true_sent_cca_hat = true_img_pca[idx] @ im_proj, true_sent_emb[idx] @ emb_proj\n",
    "calculate_corr(true_img_cca_hat, true_sent_cca_hat, true_img_cca_mean, true_sent_cca_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74fb32a-323e-4c2f-914e-fa3f693b19c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Check on overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0acad22a-09b0-46cf-8f9e-54ad187a7213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_true_img_pca = torch.load('true_data_img_pca.pt').cpu().numpy()[DATA_SIZE:DATA_SIZE+1000]\n",
    "# test_true_sent_emb = torch.load('true_data_sent_embedding.pt').cpu().numpy()[DATA_SIZE:DATA_SIZE+1000]\n",
    "# test_true_img_cca_hat, test_true_sent_cca_hat = cca.transform(test_true_img_pca, test_true_sent_emb)\n",
    "# calculate_corr(test_true_img_cca_hat, test_true_sent_cca_hat, true_img_cca_mean, true_sent_cca_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce8f0c4-00a0-4e93-a145-cc7ead4bf4e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## CCA over trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfea187-ad3f-440a-b5bc-352d5ba1cf47",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e46dae4-0c01-41b8-bf8e-8c914a5ce4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = 'worew' # without reweighting\n",
    "enc_img = EncImg(128).to(device, torch.float32)\n",
    "dec_img = DecImg(128).to(device, torch.float32)\n",
    "enc_txt = EncTxt(1590, 128).to(device, torch.float32)\n",
    "dec_txt = DecTxt(1590, 128).to(device, torch.float32)\n",
    "vae = poisevae.POISEVAE([enc_img, enc_txt], [dec_img, dec_txt], likelihoods=[Laplace, Categorical], \n",
    "                        latent_dims=[128, (128, 1, 1)], batch_size=2048, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0acef8a0-e946-491d-bc53-593f40dbe99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_img = true_img.to(device, torch.float32).split(2048, dim=0)\n",
    "true_txt = true_txt.to(device, torch.float32).split(2048, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "682d4e35-027e-4f7e-909b-87a64eb4a7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = {'model': [], 'mode': [], 'correlation': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cae629e-55dc-44ad-8b5d-3d145fdfc404",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/5 [01:42<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_179056/2038317829.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mcorr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'POISE-VAE'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_179056/2365272097.py\u001b[0m in \u001b[0;36meval_model\u001b[0;34m(vae)\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0msent_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_txt_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_txt_emb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m's2i'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_txt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_gibbs_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                     \u001b[0mgen_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_rec'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'joint'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/vae_project/POISEVAE/poisevae/POISE_VAE.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, n_gibbs_iter)\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0mrecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 \u001b[0mx_rec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlikelihoods\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx_rec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                     \u001b[0mrecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/distributions/laplace.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLaplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                     raise ValueError(\n\u001b[1;32m     56\u001b[0m                         \u001b[0;34mf\"Expected parameter {param} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for _ in tqdm(range(5)):\n",
    "    for path in glob.glob('../example/runs/CUB/worew/*'):\n",
    "        try:\n",
    "            vae, _, _ = poisevae.utils.load_checkpoint(vae, load_path=os.path.join(path, 'training_50.pt'))\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "        results = eval_model(vae)\n",
    "        for mode, val in results:\n",
    "            corr['model'].append('POISE-VAE')\n",
    "            corr['mode'].append(mode)\n",
    "            corr['correlation'].append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edc99e4-804d-4f1a-8344-93ba293c98a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = pd.DataFrame(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb556ca-6200-428a-82b9-7495ee005b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr.to_csv('_CCA_poise.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef683fff-b48e-4631-aeb3-e8813380b4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr.groupby(['model', 'mode']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ddb987-af04-417a-83c1-2bb76f98f3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr.groupby(['model', 'mode']).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fcfe41-2490-468c-86c9-1a21f057d2db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
