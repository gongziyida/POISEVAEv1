{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eb0457c-26d9-4df7-8fec-5fc8d29d4ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.distributions import Laplace\n",
    "import poisevae\n",
    "from poisevae.datasets import CUB\n",
    "from poisevae.utils import NN_lookup, Categorical, sent_emb\n",
    "from poisevae.networks.CUBNetworks import EncImg, DecImg, EncTxt, DecTxt\n",
    "\n",
    "from sklearn.cross_decomposition import CCA\n",
    "\n",
    "# from cca import *\n",
    "\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 20\n",
    "plt.rcParams['font.weight'] = 'normal'\n",
    "plt.rcParams['mathtext.fontset'] = 'cm'\n",
    "plt.rcParams['text.usetex'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fffd3d4-3bd4-4ad6-a7ed-07190f013e63",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Declarations & Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4873bbb-ba73-44a7-9dfa-a142edbbf974",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68205657-3d7e-4628-bc1a-1d2d0f90bb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_PATH = os.path.expanduser('~')\n",
    "DATA_PATH = os.path.join(HOME_PATH, 'Datasets/CUB/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "492f04ea-cff7-4527-a677-2809e4f96683",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SIZE = 81920\n",
    "true_img = torch.load('true_data_img.pt')[:DATA_SIZE]\n",
    "true_txt = torch.load('true_data_txt.pt')[:DATA_SIZE]\n",
    "true_img_pca = torch.load('true_data_img_pca.pt').cpu().numpy()[:DATA_SIZE]\n",
    "true_sent_emb = torch.load('true_data_sent_embedding.pt').cpu().numpy()[:DATA_SIZE]\n",
    "sent_PC = torch.load('sentence_emb_PC.pt').to(device, torch.float32)\n",
    "img_PC = torch.load('image_PC.pt').to(device, torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aafea47f-af65-4dc2-9341-38bbf8f3f811",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_PATH, 'cub/oc:3_msl:32/cub.emb'), 'rb') as file:\n",
    "    emb = pickle.load(file)\n",
    "with open(os.path.join(DATA_PATH, 'cub/oc:3_msl:32/cub.weights'), 'rb') as file:\n",
    "    weights = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e1e5b9c-bb34-479b-991c-dc456452f6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_transform(X, PC):\n",
    "    li = X.split(2048, 0)\n",
    "    return torch.cat([e - torch.matmul(PC, e.unsqueeze(-1)).squeeze() for e in li])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "108f69df-afac-4da0-bdc6-8c55266c9cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_corr(imgs, txts, true_img_mean, true_txt_mean):\n",
    "    if isinstance(imgs, np.ndarray):\n",
    "        imgs = torch.from_numpy(imgs)\n",
    "    if isinstance(txts, np.ndarray):\n",
    "        txts = torch.from_numpy(txts)\n",
    "    if isinstance(true_img_mean, np.ndarray):\n",
    "        true_img_mean = torch.from_numpy(true_img_mean)\n",
    "    if isinstance(true_txt_mean, np.ndarray):\n",
    "        true_txt_mean = torch.from_numpy(true_txt_mean)\n",
    "    # Assume all are projected\n",
    "    corr = F.cosine_similarity((imgs.cpu() - true_img_mean.cpu()), \n",
    "                               (txts.cpu() - true_txt_mean.cpu())).mean()\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c169391a-70e8-432d-a2c3-cbf53297f5e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## CCA over truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ade1f9e-0308-4f2a-8684-393933256b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('CCA_model.pkl', 'rb') as f:\n",
    "        cca = pickle.load(f)\n",
    "except FileNotFoundError:\n",
    "    cca = CCA(n_components=10, tol=1e-4)\n",
    "    cca.fit(true_img_pca, true_sent_emb)\n",
    "    with open('CCA_model.pkl','wb') as f:\n",
    "        pickle.dump(cca, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a7be008-33f6-489c-aa77-efd1360abac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4875, dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_img_cca, true_sent_cca = cca.transform(true_img_pca, true_sent_emb)\n",
    "true_img_cca_mean, true_sent_cca_mean =  true_img_cca.mean(axis=0), true_sent_cca.mean(axis=0)\n",
    "calculate_corr(true_img_cca, true_sent_cca, true_img_cca_mean, true_sent_cca_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a16a867-05f2-4666-8a06-2812b34ca78a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Check on convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd940e42-e849-490c-b189-d5929a6a8ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4875, dtype=torch.float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.arange(true_img_pca.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "true_img_cca_hat, true_sent_cca_hat = cca.transform(true_img_pca[idx], true_sent_emb[idx])\n",
    "calculate_corr(true_img_cca_hat, true_sent_cca_hat, true_img_cca_mean, true_sent_cca_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74fb32a-323e-4c2f-914e-fa3f693b19c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Check on overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0acad22a-09b0-46cf-8f9e-54ad187a7213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4462, dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_true_img_pca = torch.load('true_data_img_pca.pt').cpu().numpy()[DATA_SIZE:DATA_SIZE+1000]\n",
    "test_true_sent_emb = torch.load('true_data_sent_embedding.pt').cpu().numpy()[DATA_SIZE:DATA_SIZE+1000]\n",
    "test_true_img_cca_hat, test_true_sent_cca_hat = cca.transform(test_true_img_pca, test_true_sent_emb)\n",
    "calculate_corr(test_true_img_cca_hat, test_true_sent_cca_hat, true_img_cca_mean, true_sent_cca_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce8f0c4-00a0-4e93-a145-cc7ead4bf4e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## CCA over trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfea187-ad3f-440a-b5bc-352d5ba1cf47",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e46dae4-0c01-41b8-bf8e-8c914a5ce4ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_img = EncImg(128).to(device)\n",
    "dec_img = DecImg(128).to(device)\n",
    "enc_txt = EncTxt(1590, 128).to(device)\n",
    "dec_txt = DecTxt(1590, 128).to(device)\n",
    "vae = poisevae.POISEVAE([enc_img, enc_txt], [dec_img, dec_txt], likelihoods=[Laplace, Categorical], \n",
    "                        latent_dims=[128, (128, 1, 1)]).to(device)\n",
    "vae, _, epoch = poisevae.utils.load_checkpoint(vae, load_path=sorted(glob.glob('../example/runs/CUB/worew/train*.pt'))[-1])\n",
    "epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05562b2a-df0d-404a-9617-d81ca40fad03",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f1c1466-3357-4d0f-a71b-b39930f57716",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_txt_emb = []\n",
    "rec_img = []\n",
    "with torch.no_grad():\n",
    "    true_img_split = true_img.to(device, torch.float32).split(2048, dim=0)\n",
    "    true_txt_split = true_txt.to(device, torch.float32).split(2048, dim=0)\n",
    "    \n",
    "    for i in range(len(true_img_split)):\n",
    "        results = vae([true_img_split[i], true_txt_split[i]])\n",
    "\n",
    "        rec_img_i = results['x_rec'][0].loc\n",
    "        rec_img.append(rec_img_i)\n",
    "        \n",
    "        rec_txt_i = results['x_rec'][1].probs.argmax(dim=1).reshape(rec_img_i.shape[0], -1)\n",
    "        rec_txt_emb.append(np.zeros((rec_img_i.shape[0], emb.shape[1])))\n",
    "        sent_emb(rec_txt_i.cpu().numpy().astype(np.int32), emb, weights, rec_txt_emb[-1])\n",
    "            \n",
    "rec_img = torch.cat(rec_img).to(device, torch.float32)\n",
    "rec_txt_emb = torch.from_numpy(np.vstack(rec_txt_emb)).to(device, torch.float32)\n",
    "true_img_split, true_txt_split = None, None # Free CUDA memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56dd0431-44aa-4da4-9c39-925d8b6beca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_txt_emb_pca = pca_transform(rec_txt_emb, sent_PC.to(device, torch.float32)).cpu().numpy()\n",
    "rec_img_pca = pca_transform(rec_img, img_PC.to(device, torch.float32)).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cd04470-6151-4059-89db-c05d66a9b461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4356, dtype=torch.float64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_img_cca, rec_sent_cca = cca.transform(rec_img_pca, rec_txt_emb_pca)\n",
    "calculate_corr(rec_img_cca, rec_sent_cca, true_img_cca_mean, true_sent_cca_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f08d53b-c7f3-48cc-86a6-9630cb8e9a5f",
   "metadata": {},
   "source": [
    "### Cross Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c111f8e-d933-452c-8873-dcd642bbd3da",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Image -> Caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "165381b5-259f-478d-b45b-6d7e326189e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_txt_emb = []\n",
    "rec_img = []\n",
    "with torch.no_grad():\n",
    "    true_img_split = true_img.to(device, torch.float32).split(2048, dim=0)\n",
    "    true_txt_split = true_txt.to(device, torch.float32).split(2048, dim=0)\n",
    "    \n",
    "    for i in range(len(true_img_split)):\n",
    "        results = vae([true_img_split[i], None])\n",
    "\n",
    "        rec_img_i = results['x_rec'][0].loc\n",
    "        rec_img.append(rec_img_i)\n",
    "        \n",
    "        rec_txt_i = results['x_rec'][1].probs.argmax(dim=1).reshape(rec_img_i.shape[0], -1)\n",
    "        rec_txt_emb.append(np.zeros((rec_img_i.shape[0], emb.shape[1])))\n",
    "        sent_emb(rec_txt_i.cpu().numpy().astype(np.int32), emb, weights, rec_txt_emb[-1])\n",
    "            \n",
    "rec_img = torch.cat(rec_img).to(device, torch.float32)\n",
    "rec_txt_emb = torch.from_numpy(np.vstack(rec_txt_emb)).to(device, torch.float32)\n",
    "true_img_split, true_txt_split = None, None # Free CUDA memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce397318-9df4-4d3a-a768-1fa835484773",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_txt_emb_pca = pca_transform(rec_txt_emb, sent_PC.to(device, torch.float32)).cpu().numpy()\n",
    "rec_img_pca = pca_transform(rec_img, img_PC.to(device, torch.float32)).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f72555ed-fe4d-42ce-8a00-02ee803d4acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3963, dtype=torch.float64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_img_cca, rec_sent_cca = cca.transform(rec_img_pca, rec_txt_emb_pca)\n",
    "calculate_corr(rec_img_cca, rec_sent_cca, true_img_cca_mean, true_sent_cca_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d0bb94-2ffd-45b3-ad07-6eec3b394a6e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Image <- Caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0315b6ee-d4b2-470d-a0be-a55d73c35456",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_txt_emb = []\n",
    "rec_img = []\n",
    "with torch.no_grad():\n",
    "    true_img_split = true_img.to(device, torch.float32).split(2048, dim=0)\n",
    "    true_txt_split = true_txt.to(device, torch.float32).split(2048, dim=0)\n",
    "    \n",
    "    for i in range(len(true_img_split)):\n",
    "        results = vae([None, true_txt_split[i]])\n",
    "\n",
    "        rec_img_i = results['x_rec'][0].loc\n",
    "        rec_img.append(rec_img_i)\n",
    "        \n",
    "        rec_txt_i = results['x_rec'][1].probs.argmax(dim=1).reshape(rec_img_i.shape[0], -1)\n",
    "        rec_txt_emb.append(np.zeros((rec_img_i.shape[0], emb.shape[1])))\n",
    "        sent_emb(rec_txt_i.cpu().numpy().astype(np.int32), emb, weights, rec_txt_emb[-1])\n",
    "            \n",
    "rec_img = torch.cat(rec_img).to(device, torch.float32)\n",
    "rec_txt_emb = torch.from_numpy(np.vstack(rec_txt_emb)).to(device, torch.float32)\n",
    "true_img_split, true_txt_split = None, None # Free CUDA memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7061466c-0070-4225-bf67-f638168fa134",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_txt_emb_pca = pca_transform(rec_txt_emb, sent_PC.to(device, torch.float32)).cpu().numpy()\n",
    "rec_img_pca = pca_transform(rec_img, img_PC.to(device, torch.float32)).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79a2f35a-2eff-4a97-8ae5-489f84a4441f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3837, dtype=torch.float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_img_cca, rec_sent_cca = cca.transform(rec_img_pca, rec_txt_emb_pca)\n",
    "calculate_corr(rec_img_cca, rec_sent_cca, true_img_cca_mean, true_sent_cca_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0af047-d58d-412d-b5c9-41d054ba0701",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Joint Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1f208fd-4153-445e-b326-bd85fa4ea4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_txt_emb = []\n",
    "rec_img = []\n",
    "with torch.no_grad():\n",
    "    true_img_split = true_img.to(device, torch.float32).split(2048, dim=0)\n",
    "    true_txt_split = true_txt.to(device, torch.float32).split(2048, dim=0)\n",
    "    \n",
    "    for i in range(len(true_img_split)):\n",
    "        results = vae([None, None])\n",
    "\n",
    "        rec_img_i = results['x_rec'][0].loc\n",
    "        rec_img.append(rec_img_i)\n",
    "        \n",
    "        rec_txt_i = results['x_rec'][1].probs.argmax(dim=1).reshape(rec_img_i.shape[0], -1)\n",
    "        rec_txt_emb.append(np.zeros((rec_img_i.shape[0], emb.shape[1])))\n",
    "        sent_emb(rec_txt_i.cpu().numpy().astype(np.int32), emb, weights, rec_txt_emb[-1])\n",
    "            \n",
    "rec_img = torch.cat(rec_img).to(device, torch.float32)\n",
    "rec_txt_emb = torch.from_numpy(np.vstack(rec_txt_emb)).to(device, torch.float32)\n",
    "true_img_split, true_txt_split = None, None # Free CUDA memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8bb7464-db43-42d8-a720-80b788b99df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_txt_emb_pca = pca_transform(rec_txt_emb, sent_PC.to(device, torch.float32)).cpu().numpy()\n",
    "rec_img_pca = pca_transform(rec_img, img_PC.to(device, torch.float32)).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2575c18b-f873-4164-90a4-7c5c81942b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3659, dtype=torch.float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_img_cca, rec_sent_cca = cca.transform(rec_img_pca, rec_txt_emb_pca)\n",
    "calculate_corr(rec_img_cca, rec_sent_cca, true_img_cca_mean, true_sent_cca_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd473da-4693-4262-b5c4-071732d9c7a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
