{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eb0457c-26d9-4df7-8fec-5fc8d29d4ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.distributions import Laplace\n",
    "import poisevae\n",
    "from poisevae.datasets import CUB\n",
    "from poisevae.utils import NN_lookup, Categorical, sent_emb\n",
    "from poisevae.networks.CUBNetworks import EncImg, DecImg, EncTxt, DecTxt\n",
    "\n",
    "from sklearn.cross_decomposition import CCA\n",
    "\n",
    "# from cca import *\n",
    "\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 20\n",
    "plt.rcParams['font.weight'] = 'normal'\n",
    "plt.rcParams['mathtext.fontset'] = 'cm'\n",
    "plt.rcParams['text.usetex'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fffd3d4-3bd4-4ad6-a7ed-07190f013e63",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Declarations & Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4873bbb-ba73-44a7-9dfa-a142edbbf974",
   "metadata": {},
   "outputs": [],
   "source": [
    "device ='cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68205657-3d7e-4628-bc1a-1d2d0f90bb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_PATH = os.path.expanduser('~')\n",
    "DATA_PATH = os.path.join(HOME_PATH, 'Datasets/CUB/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "492f04ea-cff7-4527-a677-2809e4f96683",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SIZE = 81920\n",
    "true_img = torch.load('../../true_data_img.pt')[:DATA_SIZE]\n",
    "true_txt = torch.load('../../true_data_txt.pt')[:DATA_SIZE]\n",
    "true_img_pca = torch.load('../../true_data_img_pca.pt').cpu().numpy()[:DATA_SIZE]\n",
    "true_sent_emb = torch.load('../../true_data_sent_embedding.pt').cpu().numpy()[:DATA_SIZE]\n",
    "sent_PC = torch.load('../../sentence_emb_PC.pt').to(device, torch.float32)\n",
    "img_PC = torch.load('../../image_PC.pt').to(device, torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aafea47f-af65-4dc2-9341-38bbf8f3f811",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_PATH, 'cub/oc:3_msl:32/cub.emb'), 'rb') as file:\n",
    "    emb = pickle.load(file)\n",
    "with open(os.path.join(DATA_PATH, 'cub/oc:3_msl:32/cub.weights'), 'rb') as file:\n",
    "    weights = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e1e5b9c-bb34-479b-991c-dc456452f6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_transform(X, PC):\n",
    "    li = X.split(2048, 0)\n",
    "    return torch.cat([e - torch.matmul(PC, e.unsqueeze(-1)).squeeze() for e in li])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "108f69df-afac-4da0-bdc6-8c55266c9cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_corr(imgs, txts, true_img_mean, true_txt_mean):\n",
    "    if isinstance(imgs, np.ndarray):\n",
    "        imgs = torch.from_numpy(imgs)\n",
    "    if isinstance(txts, np.ndarray):\n",
    "        txts = torch.from_numpy(txts)\n",
    "    if isinstance(true_img_mean, np.ndarray):\n",
    "        true_img_mean = torch.from_numpy(true_img_mean)\n",
    "    if isinstance(true_txt_mean, np.ndarray):\n",
    "        true_txt_mean = torch.from_numpy(true_txt_mean)\n",
    "    # Assume all are projected\n",
    "    corr = F.cosine_similarity((imgs.cpu() - true_img_mean.cpu()), \n",
    "                               (txts.cpu() - true_txt_mean.cpu())).mean()\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ff7266b-dc83-4a8b-aaec-abdfe51d3248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_cca(gen_img=None, gen_txt_emb=None):\n",
    "    if gen_img is not None:\n",
    "        gen_img = torch.cat(gen_img).to(device, torch.float32)\n",
    "        gen_img = pca_transform(gen_img, img_PC.to(device, torch.float32)).cpu().numpy()\n",
    "    else:\n",
    "        gen_img = true_img_pca\n",
    "        \n",
    "    if gen_txt_emb is not None: \n",
    "        gen_txt_emb = torch.from_numpy(np.vstack(gen_txt_emb)).to(device, torch.float32)\n",
    "        gen_txt_emb = pca_transform(gen_txt_emb, sent_PC.to(device, torch.float32)).cpu().numpy()\n",
    "    else:\n",
    "        gen_txt_emb = true_sent_emb\n",
    "    \n",
    "    gen_img_cca, gen_sent_cca = cca.transform(gen_img, gen_txt_emb)\n",
    "    return float(calculate_corr(gen_img_cca, gen_sent_cca, true_img_cca_mean, true_sent_cca_mean))\n",
    "\n",
    "def eval_model(vae, mode, condition):\n",
    "    corr = []\n",
    "    for path in glob.glob('../example/runs/CUB/%s/*' % condition):\n",
    "        try:\n",
    "            vae, _, _ = poisevae.utils.load_checkpoint(vae, load_path=os.path.join(path, 'training_40.pt'))\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "        vae = vae.to(device, torch.float32)\n",
    "        gen_txt_emb = []\n",
    "        gen_img = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(len(true_img)):\n",
    "                if mode == 'i2s':\n",
    "                    results = vae([true_img[i], None])\n",
    "                    gen_txt_i = results['x_rec'][1].probs.argmax(dim=1).reshape(true_img[i].shape[0], -1)\n",
    "                    gen_txt_emb.append(np.zeros((true_img[i].shape[0], emb.shape[1])))\n",
    "                    sent_emb(gen_txt_i.cpu().numpy().astype(np.int32), emb, weights, gen_txt_emb[-1])\n",
    "                elif mode == 's2i':\n",
    "                    results = vae([None, true_txt[i]])\n",
    "                    gen_img.append(results['x_rec'][0].loc)\n",
    "                elif mode == 'joint':\n",
    "                    results = vae([None, None])\n",
    "                    gen_img.append(results['x_rec'][0].loc)\n",
    "                    gen_txt_i = results['x_rec'][1].probs.argmax(dim=1).reshape(true_img[i].shape[0], -1)\n",
    "                    gen_txt_emb.append(np.zeros((true_img[i].shape[0], emb.shape[1])))\n",
    "                    sent_emb(gen_txt_i.cpu().numpy().astype(np.int32), emb, weights, gen_txt_emb[-1])\n",
    "                else: \n",
    "                    raise ValueError\n",
    "\n",
    "            if mode == 'i2s':\n",
    "                corr.append(perform_cca(gen_txt_emb=gen_txt_emb))\n",
    "            elif mode == 's2i':\n",
    "                corr.append(perform_cca(gen_img=gen_img))\n",
    "            elif mode == 'joint':\n",
    "                corr.append(perform_cca(gen_img=gen_img, gen_txt_emb=gen_txt_emb))\n",
    "            else: \n",
    "                raise ValueError \n",
    "            \n",
    "    return corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c169391a-70e8-432d-a2c3-cbf53297f5e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## CCA over truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ade1f9e-0308-4f2a-8684-393933256b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('CCA_model.pkl', 'rb') as f:\n",
    "        cca = pickle.load(f)\n",
    "except FileNotFoundError:\n",
    "    cca = CCA(n_components=10, tol=1e-4)\n",
    "    cca.fit(true_img_pca, true_sent_emb)\n",
    "    with open('CCA_model.pkl','wb') as f:\n",
    "        pickle.dump(cca, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a7be008-33f6-489c-aa77-efd1360abac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4875, dtype=torch.float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_img_cca, true_sent_cca = cca.transform(true_img_pca, true_sent_emb)\n",
    "true_img_cca_mean, true_sent_cca_mean =  true_img_cca.mean(axis=0), true_sent_cca.mean(axis=0)\n",
    "calculate_corr(true_img_cca, true_sent_cca, true_img_cca_mean, true_sent_cca_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a16a867-05f2-4666-8a06-2812b34ca78a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Check on convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd940e42-e849-490c-b189-d5929a6a8ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4875, dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.arange(true_img_pca.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "true_img_cca_hat, true_sent_cca_hat = cca.transform(true_img_pca[idx], true_sent_emb[idx])\n",
    "calculate_corr(true_img_cca_hat, true_sent_cca_hat, true_img_cca_mean, true_sent_cca_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74fb32a-323e-4c2f-914e-fa3f693b19c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Check on overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0acad22a-09b0-46cf-8f9e-54ad187a7213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_true_img_pca = torch.load('true_data_img_pca.pt').cpu().numpy()[DATA_SIZE:DATA_SIZE+1000]\n",
    "# test_true_sent_emb = torch.load('true_data_sent_embedding.pt').cpu().numpy()[DATA_SIZE:DATA_SIZE+1000]\n",
    "# test_true_img_cca_hat, test_true_sent_cca_hat = cca.transform(test_true_img_pca, test_true_sent_emb)\n",
    "# calculate_corr(test_true_img_cca_hat, test_true_sent_cca_hat, true_img_cca_mean, true_sent_cca_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce8f0c4-00a0-4e93-a145-cc7ead4bf4e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## CCA over trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfea187-ad3f-440a-b5bc-352d5ba1cf47",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e46dae4-0c01-41b8-bf8e-8c914a5ce4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = 'worew' # without reweighting\n",
    "enc_img = EncImg(128).to(device, torch.float32)\n",
    "dec_img = DecImg(128).to(device, torch.float32)\n",
    "enc_txt = EncTxt(1590, 128).to(device, torch.float32)\n",
    "dec_txt = DecTxt(1590, 128).to(device, torch.float32)\n",
    "vae = poisevae.POISEVAE([enc_img, enc_txt], [dec_img, dec_txt], likelihoods=[Laplace, Categorical], \n",
    "                        latent_dims=[128, (128, 1, 1)], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0acef8a0-e946-491d-bc53-593f40dbe99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_img = true_img.to(device, torch.float32).split(2048, dim=0)\n",
    "true_txt = true_txt.to(device, torch.float32).split(2048, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f08d53b-c7f3-48cc-86a6-9630cb8e9a5f",
   "metadata": {},
   "source": [
    "### Cross Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c111f8e-d933-452c-8873-dcd642bbd3da",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Image -> Caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3db85849-d822-4ff5-a649-131608022b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3873777559642452, 0.3476689747878726, 0.3324589801101878]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = eval_model(vae, 'i2s', condition)\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d0bb94-2ffd-45b3-ad07-6eec3b394a6e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Image <- Caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90df4fe0-ed8f-48c3-91bd-94d95a0d8cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.012597809681969089, -0.006929092858105511, 0.032757421965073676]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = eval_model(vae, 's2i', condition)\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0af047-d58d-412d-b5c9-41d054ba0701",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Joint Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "155ac87f-4fc5-43bb-a061-5217b2925a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5120772018741817, 0.3761393199694043, 0.31803801406889864]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = eval_model(vae, 'joint', condition)\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd473da-4693-4262-b5c4-071732d9c7a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
