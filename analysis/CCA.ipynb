{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eb0457c-26d9-4df7-8fec-5fc8d29d4ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.distributions import Laplace\n",
    "import poisevae\n",
    "from poisevae.datasets import CUB\n",
    "from poisevae.utils import NN_lookup, Categorical, sent_emb\n",
    "from poisevae.networks.CUBNetworks import EncImg, DecImg, EncTxt, DecTxt\n",
    "\n",
    "from sklearn.cross_decomposition import CCA\n",
    "\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 20\n",
    "plt.rcParams['font.weight'] = 'normal'\n",
    "plt.rcParams['mathtext.fontset'] = 'cm'\n",
    "plt.rcParams['text.usetex'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fffd3d4-3bd4-4ad6-a7ed-07190f013e63",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Declarations & Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4873bbb-ba73-44a7-9dfa-a142edbbf974",
   "metadata": {},
   "outputs": [],
   "source": [
    "device ='cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68205657-3d7e-4628-bc1a-1d2d0f90bb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_PATH = os.path.expanduser('~')\n",
    "DATA_PATH = os.path.join(HOME_PATH, 'Datasets/CUB/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "492f04ea-cff7-4527-a677-2809e4f96683",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SIZE = 81920\n",
    "true_img = torch.load('../../true_data_img.pt')[:DATA_SIZE]\n",
    "true_txt = torch.load('../../true_data_txt.pt')[:DATA_SIZE]\n",
    "true_img_pca = torch.load('../../true_data_img_pca.pt').cpu().numpy()[:DATA_SIZE]\n",
    "true_sent_emb = torch.load('../../true_data_sent_embedding.pt').cpu().numpy()[:DATA_SIZE]\n",
    "sent_PC = torch.load('../../sentence_emb_PC.pt').to(device, torch.float32)\n",
    "img_PC = torch.load('../../image_PC.pt').to(device, torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aafea47f-af65-4dc2-9341-38bbf8f3f811",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_PATH, 'cub/oc:3_msl:32/cub.emb'), 'rb') as file:\n",
    "    emb = pickle.load(file)\n",
    "with open(os.path.join(DATA_PATH, 'cub/oc:3_msl:32/cub.weights'), 'rb') as file:\n",
    "    weights = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e1e5b9c-bb34-479b-991c-dc456452f6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_transform(X, PC):\n",
    "    li = X.split(2048, 0)\n",
    "    return torch.cat([e - torch.matmul(PC, e.unsqueeze(-1)).squeeze() for e in li])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "108f69df-afac-4da0-bdc6-8c55266c9cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_corr(imgs, txts, true_img_mean, true_txt_mean):\n",
    "    if isinstance(imgs, np.ndarray):\n",
    "        imgs = torch.from_numpy(imgs)\n",
    "    if isinstance(txts, np.ndarray):\n",
    "        txts = torch.from_numpy(txts)\n",
    "    if isinstance(true_img_mean, np.ndarray):\n",
    "        true_img_mean = torch.from_numpy(true_img_mean)\n",
    "    if isinstance(true_txt_mean, np.ndarray):\n",
    "        true_txt_mean = torch.from_numpy(true_txt_mean)\n",
    "    # Assume all are projected\n",
    "    corr = F.cosine_similarity((imgs.cpu() - true_img_mean.cpu()), \n",
    "                               (txts.cpu() - true_txt_mean.cpu())).mean()\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05c12880-864b-4f32-9159-c47fa9d94315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_cca(gen_img=None, gen_txt_emb=None):\n",
    "    if gen_img is not None:\n",
    "        gen_img = torch.cat(gen_img).to(device, torch.float32)\n",
    "        gen_img = pca_transform(gen_img, img_PC.to(device, torch.float32)).cpu().numpy()\n",
    "    else:\n",
    "        gen_img = true_img_pca\n",
    "        \n",
    "    if gen_txt_emb is not None: \n",
    "        gen_txt_emb = torch.from_numpy(np.vstack(gen_txt_emb)).to(device, torch.float32)\n",
    "        gen_txt_emb = pca_transform(gen_txt_emb, sent_PC.to(device, torch.float32)).cpu().numpy()\n",
    "    else:\n",
    "        gen_txt_emb = true_sent_emb\n",
    "    \n",
    "    gen_img_cca, gen_sent_cca = cca.transform(gen_img, gen_txt_emb)\n",
    "    return float(calculate_corr(gen_img_cca, gen_sent_cca, true_img_cca_mean, true_sent_cca_mean))\n",
    "\n",
    "def eval_model(vae):\n",
    "    corr = []\n",
    "    for mode in ('joint', 'i2s', 's2i'):\n",
    "        gen_txt_emb = []\n",
    "        gen_img = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(len(true_img)):\n",
    "                if mode == 'i2s':\n",
    "                    results = vae([true_img[i], None], n_gibbs_iter=50)\n",
    "                    gen_txt_i = results['x_rec'][1].probs.argmax(dim=1).reshape(true_img[i].shape[0], -1)\n",
    "                    gen_txt_emb.append(np.zeros((true_img[i].shape[0], emb.shape[1])))\n",
    "                    sent_emb(gen_txt_i.cpu().numpy().astype(np.int32), emb, weights, gen_txt_emb[-1])\n",
    "                elif mode == 's2i':\n",
    "                    results = vae([None, true_txt[i]], n_gibbs_iter=50)\n",
    "                    gen_img.append(results['x_rec'][0].loc)\n",
    "                elif mode == 'joint':\n",
    "                    results = vae.generate(true_img[i].shape[0], n_gibbs_iter=50)\n",
    "                    gen_img.append(results['x_rec'][0].loc)\n",
    "                    gen_txt_i = results['x_rec'][1].probs.argmax(dim=1).reshape(true_img[i].shape[0], -1)\n",
    "                    gen_txt_emb.append(np.zeros((true_img[i].shape[0], emb.shape[1])))\n",
    "                    sent_emb(gen_txt_i.cpu().numpy().astype(np.int32), emb, weights, gen_txt_emb[-1])\n",
    "                else: \n",
    "                    raise ValueError\n",
    "\n",
    "            if mode == 'i2s':\n",
    "                corr.append(('i2s', perform_cca(gen_txt_emb=gen_txt_emb)))\n",
    "            elif mode == 's2i':\n",
    "                corr.append(('s2i', perform_cca(gen_img=gen_img)))\n",
    "            elif mode == 'joint':\n",
    "                corr.append(('joint', perform_cca(gen_img=gen_img, gen_txt_emb=gen_txt_emb)))\n",
    "            else: \n",
    "                raise ValueError \n",
    "        del results, gen_img, gen_txt_emb # Free memory\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c169391a-70e8-432d-a2c3-cbf53297f5e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## CCA over truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ade1f9e-0308-4f2a-8684-393933256b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('CCA_model.pkl', 'rb') as f:\n",
    "        cca = pickle.load(f)\n",
    "except FileNotFoundError:\n",
    "    cca = CCA(n_components=10, tol=1e-4)\n",
    "    cca.fit(true_img_pca, true_sent_emb)\n",
    "    with open('CCA_model.pkl','wb') as f:\n",
    "        pickle.dump(cca, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a7be008-33f6-489c-aa77-efd1360abac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4875, dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_img_cca, true_sent_cca = cca.transform(true_img_pca, true_sent_emb)\n",
    "true_img_cca_mean, true_sent_cca_mean =  true_img_cca.mean(axis=0), true_sent_cca.mean(axis=0)\n",
    "calculate_corr(true_img_cca, true_sent_cca, true_img_cca_mean, true_sent_cca_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a16a867-05f2-4666-8a06-2812b34ca78a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Check on convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd940e42-e849-490c-b189-d5929a6a8ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4875, dtype=torch.float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.arange(true_img_pca.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "true_img_cca_hat, true_sent_cca_hat = cca.transform(true_img_pca[idx], true_sent_emb[idx])\n",
    "calculate_corr(true_img_cca_hat, true_sent_cca_hat, true_img_cca_mean, true_sent_cca_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74fb32a-323e-4c2f-914e-fa3f693b19c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Check on overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0acad22a-09b0-46cf-8f9e-54ad187a7213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_true_img_pca = torch.load('true_data_img_pca.pt').cpu().numpy()[DATA_SIZE:DATA_SIZE+1000]\n",
    "# test_true_sent_emb = torch.load('true_data_sent_embedding.pt').cpu().numpy()[DATA_SIZE:DATA_SIZE+1000]\n",
    "# test_true_img_cca_hat, test_true_sent_cca_hat = cca.transform(test_true_img_pca, test_true_sent_emb)\n",
    "# calculate_corr(test_true_img_cca_hat, test_true_sent_cca_hat, true_img_cca_mean, true_sent_cca_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce8f0c4-00a0-4e93-a145-cc7ead4bf4e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## CCA over trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfea187-ad3f-440a-b5bc-352d5ba1cf47",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e46dae4-0c01-41b8-bf8e-8c914a5ce4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = 'worew' # without reweighting\n",
    "enc_img = EncImg(128).to(device, torch.float32)\n",
    "dec_img = DecImg(128).to(device, torch.float32)\n",
    "enc_txt = EncTxt(1590, 128).to(device, torch.float32)\n",
    "dec_txt = DecTxt(1590, 128).to(device, torch.float32)\n",
    "vae = poisevae.POISEVAE([enc_img, enc_txt], [dec_img, dec_txt], likelihoods=[Laplace, Categorical], \n",
    "                        latent_dims=[128, (128, 1, 1)], batch_size=2048, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0acef8a0-e946-491d-bc53-593f40dbe99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_img = true_img.to(device, torch.float32).split(2048, dim=0)\n",
    "true_txt = true_txt.to(device, torch.float32).split(2048, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "682d4e35-027e-4f7e-909b-87a64eb4a7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = {'model': [], 'mode': [], 'correlation': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cae629e-55dc-44ad-8b5d-3d145fdfc404",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in tqdm(range(5)):\n",
    "    for modname, modelname in zip(('worew', 'wrew'), ('POISE-VAE', 'POISE-VAE*')):\n",
    "        for path in glob.glob('../example/runs/CUB/%s/*' % modname):\n",
    "            try:\n",
    "                vae, _, _ = poisevae.utils.load_checkpoint(vae, load_path=os.path.join(path, 'training_50.pt'))\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "            results = eval_model(vae)\n",
    "            for mode, val in results:\n",
    "                corr['model'].append(modelname)\n",
    "                corr['mode'].append(mode)\n",
    "                corr['correlation'].append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3edc99e4-804d-4f1a-8344-93ba293c98a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = pd.DataFrame(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ebb556ca-6200-428a-82b9-7495ee005b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr.to_csv('CCA_poise.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ef683fff-b48e-4631-aeb3-e8813380b4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>mode</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">POISE-VAE</th>\n",
       "      <th>i2s</th>\n",
       "      <td>0.349495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joint</th>\n",
       "      <td>0.335744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s2i</th>\n",
       "      <td>0.143429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">POISE-VAE*</th>\n",
       "      <th>i2s</th>\n",
       "      <td>0.033019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joint</th>\n",
       "      <td>0.031961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s2i</th>\n",
       "      <td>0.065847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  correlation\n",
       "model      mode              \n",
       "POISE-VAE  i2s       0.349495\n",
       "           joint     0.335744\n",
       "           s2i       0.143429\n",
       "POISE-VAE* i2s       0.033019\n",
       "           joint     0.031961\n",
       "           s2i       0.065847"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr.groupby(['model', 'mode']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "87ddb987-af04-417a-83c1-2bb76f98f3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>mode</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">POISE-VAE</th>\n",
       "      <th>i2s</th>\n",
       "      <td>0.003378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joint</th>\n",
       "      <td>0.038780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s2i</th>\n",
       "      <td>0.024031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">POISE-VAE*</th>\n",
       "      <th>i2s</th>\n",
       "      <td>0.002069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joint</th>\n",
       "      <td>0.011168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s2i</th>\n",
       "      <td>0.001182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  correlation\n",
       "model      mode              \n",
       "POISE-VAE  i2s       0.003378\n",
       "           joint     0.038780\n",
       "           s2i       0.024031\n",
       "POISE-VAE* i2s       0.002069\n",
       "           joint     0.011168\n",
       "           s2i       0.001182"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr.groupby(['model', 'mode']).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c1ac3e-753d-4ed5-b831-510611de4bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
