{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9158965b-111f-47b8-aa8a-bc6ef0f71b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions import Normal, Laplace\n",
    "\n",
    "import poisevae\n",
    "from poisevae.datasets import MNIST_SVHN\n",
    "from poisevae.networks.MNISTSVHNNetworks import EncMNIST, DecMNIST, EncSVHN, DecSVHN\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 20\n",
    "plt.rcParams['font.weight'] = 'normal'\n",
    "plt.rcParams['mathtext.fontset'] = 'cm'\n",
    "plt.rcParams['text.usetex'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9431444e-4f93-4774-a37d-800374ea499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_PATH = os.path.expanduser('~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "789b8cf5-6c24-4175-b87b-fc7d8dc8d79a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27982ee9-eb51-4b47-b7bc-8588a5f1fe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_PATH = os.path.join(HOME_PATH, 'Datasets/MNIST/%s.pt')\n",
    "SVHN_PATH = os.path.join(HOME_PATH, 'Datasets/SVHN/%s_32x32.mat')\n",
    "\n",
    "joint_dataset_train = MNIST_SVHN(mnist_pt_path=MNIST_PATH % 'train', svhn_mat_path=SVHN_PATH % 'train')\n",
    "joint_dataset_test = MNIST_SVHN(mnist_pt_path=MNIST_PATH % 'test', svhn_mat_path=SVHN_PATH % 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91d1ad0c-b498-4726-8054-8bf6125eb9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8000\n",
    "train_loader = torch.utils.data.DataLoader(joint_dataset_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(joint_dataset_test, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa0ddfdd-29ac-44bd-8bad-ed366b6a4aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat1, lat2 = 32, 32\n",
    "enc_mnist = EncMNIST(lat1).to(device)\n",
    "dec_mnist = DecMNIST(lat1).to(device)\n",
    "enc_svhn = EncSVHN(lat2).to(device)\n",
    "dec_svhn = DecSVHN(lat2).to(device)\n",
    "    \n",
    "vae = poisevae.POISEVAE_Gibbs('autograd',\n",
    "                              [enc_mnist, enc_svhn], [dec_mnist, dec_svhn], likelihoods=[Laplace, Laplace],\n",
    "                              latent_dims=[lat1, (lat2, 1, 1)], enc_config='nu', KL_calc='derivative', \n",
    "                              batch_size=batch_size\n",
    "                             ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90f353fc-3726-4978-ba70-311d3342f810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM-RBF\n",
    "def eval_clf(train_data, test_data):\n",
    "    train_X, train_Y = train_data[0].cpu().numpy(), train_data[1].cpu().numpy()\n",
    "    test_X, test_Y = test_data[0].cpu().numpy(), test_data[1].cpu().numpy()\n",
    "    \n",
    "    clf = SVC(kernel='rbf')\n",
    "    clf.fit(train_X, train_Y)\n",
    "    Y_hat = clf.predict(test_X)\n",
    "    acc = accuracy_score(test_Y, Y_hat)\n",
    "    return clf, acc\n",
    "\n",
    "# # Logistic Regression\n",
    "# def eval_clf(train_data, test_data):\n",
    "#     train_X, train_Y = train_data[0].cpu().numpy(), train_data[1].cpu().numpy()\n",
    "#     test_X, test_Y = test_data[0].cpu().numpy(), test_data[1].cpu().numpy()\n",
    "    \n",
    "#     clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='auto', max_iter=1000)\n",
    "#     clf.fit(train_X, train_Y)\n",
    "#     Y_hat = clf.predict(test_X)\n",
    "#     acc = accuracy_score(test_Y, Y_hat)\n",
    "#     return clf, acc\n",
    "\n",
    "# # One-hot linear model\n",
    "# class LatentClassifier(nn.Module):\n",
    "#     def __init__(self, lat_dim):\n",
    "#         super(LatentClassifier, self).__init__()\n",
    "#         self.mlp = nn.Linear(lat_dim, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.mlp(x)\n",
    "    \n",
    "# def eval_clf(train_data, test_data):\n",
    "#     train_X, train_Y = train_data[0].to(device), train_data[1].to(device)#torch.nn.functional.one_hot(train_data[1], num_classes=10)\n",
    "#     test_X, test_Y = test_data[0].to(device), test_data[1].to(device)#torch.nn.functional.one_hot(test_data[1], num_classes=10)\n",
    "    \n",
    "#     clf = LatentClassifier(train_X.shape[1]).to(device)\n",
    "#     optimizer = torch.optim.Adam(clf.parameters(), lr=1e-3)\n",
    "#     clf.train()\n",
    "#     losses = []\n",
    "#     for _ in  range(40):\n",
    "#         for i in range(0, train_X.shape[0], 100):\n",
    "#             optimizer.zero_grad()\n",
    "#             Y_hat = clf(train_X[i:min(i+100, train_X.shape[0])])\n",
    "#             loss = torch.nn.functional.cross_entropy(Y_hat, train_Y[i:min(i+100, train_X.shape[0])])\n",
    "#             loss.backward() \n",
    "#             optimizer.step()\n",
    "#             losses.append(loss.item())\n",
    "#     plt.plot(losses)\n",
    "#     clf.eval()\n",
    "#     with torch.no_grad():\n",
    "#         _, Y_hat = clf(test_X).max(dim=1)\n",
    "#         return clf, (Y_hat == test_Y).sum().item() / test_Y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22d0034e-64d6-4d39-b8ce-866dc44d82f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latents(loader):\n",
    "    x, y = {'mnist': [], 'svhn': []}, []\n",
    "    for i, data in enumerate(loader):\n",
    "        y.append(data[-1])\n",
    "        data = [data[0].to(device, dtype=torch.float32), data[1].to(device, dtype=torch.float32)]\n",
    "        nu1, nu2, _, _ = vae.encode(data)\n",
    "        t1, t2 = vae.get_t()\n",
    "        mu = []\n",
    "        for nu1_i, nu2_i, t1_i, t2_i in zip(nu1, nu2, t1, t2):\n",
    "            if (nu1_i is None) and (nu2_i is None): # the Nones come together\n",
    "                mu.append(-torch.reciprocal(2 * t2_i) * t1_i)\n",
    "            else:\n",
    "                mu.append(-torch.reciprocal(2 * (t2_i + nu2_i)) * (nu1_i + t1_i))\n",
    "        x['mnist'].append(mu[0])\n",
    "        x['svhn'].append(mu[1])\n",
    "        # G = vae.get_G()\n",
    "        # _, t2 = vae.get_t()\n",
    "        # z, _ = vae._sampling(G.detach(), *ret, t2, n_iterations=50)\n",
    "        # x['mnist'].append(z[0])\n",
    "        # x['svhn'].append(z[1])\n",
    "    y = torch.cat(y, 0)\n",
    "    x['mnist'] = torch.cat(x['mnist'], 0)#.flatten(end_dim=1)\n",
    "    x['svhn'] = torch.cat(x['svhn'], 0)#.flatten(end_dim=1)\n",
    "    print(x['svhn'].shape)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9948b480-cf9f-4f1e-984e-43e207002083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([56000, 32])\n",
      "torch.Size([8000, 32])\n"
     ]
    }
   ],
   "source": [
    "# paths = glob.glob('../example/runs/MNIST_SVHN/fix_t/22*')\n",
    "paths = [None]\n",
    "\n",
    "clf_models = {'model': [], 'latent space': [], 'accuracy': [], 'classifier': []}\n",
    "\n",
    "for path in paths:\n",
    "    # vae, _, _ = poisevae.utils.load_checkpoint(vae, load_path=os.path.join(path, 'training_200.pt'))\n",
    "    vae, _, epoch = poisevae.utils.load_checkpoint(vae, load_path='training_200.pt')\n",
    "    with torch.no_grad():\n",
    "        clf_train_x, clf_train_y = get_latents(train_loader)\n",
    "        clf_test_x, clf_test_y = get_latents(test_loader)\n",
    "        \n",
    "    for i, lat_space in enumerate(('mnist', 'svhn')):\n",
    "        clf_models['model'].append('POISE-VAE')\n",
    "        clf_models['latent space'].append(lat_space)\n",
    "        results = eval_clf([clf_train_x[lat_space], clf_train_y], \n",
    "                           [clf_test_x[lat_space], clf_test_y])\n",
    "        clf_models['classifier'].append(results[0])\n",
    "        clf_models['accuracy'].append(results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7228298-5aa8-4e94-86e4-ed7d1727c67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>latent space</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POISE-VAE</td>\n",
       "      <td>mnist</td>\n",
       "      <td>0.929125</td>\n",
       "      <td>SVC()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POISE-VAE</td>\n",
       "      <td>svhn</td>\n",
       "      <td>0.688750</td>\n",
       "      <td>SVC()</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model latent space  accuracy classifier\n",
       "0  POISE-VAE        mnist  0.929125      SVC()\n",
       "1  POISE-VAE         svhn  0.688750      SVC()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017a1fb3-0c07-4de1-8aac-23606039c3fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
