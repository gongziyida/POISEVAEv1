{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ad62d0b-55f6-4e07-b67b-fcdbfa531d3f",
   "metadata": {},
   "source": [
    "## FastText Embedding for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b063a32d-715e-4d2d-819e-79e33646f622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import poisevae\n",
    "from poisevae.utils import sent_emb\n",
    "from poisevae.datasets import CUB\n",
    "\n",
    "from cca import pca_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21213870-44cd-4b8f-bac7-28f5146256c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_PATH = os.path.expanduser('~')\n",
    "DATA_PATH = os.path.join(HOME_PATH, 'Datasets/CUB/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e07e4985-a2e3-4fca-94e3-297a5bd9544c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code is adapted from https://github.com/iffsid/mmvae, the repository for the work\n",
    "# Y. Shi, N. Siddharth, B. Paige and PHS. Torr.\n",
    "# Variational Mixture-of-Experts Autoencoders for Multi-Modal Deep Generative Models.\n",
    "# In Proceedings of the 33rd International Conference on Neural Information Processing Systems,\n",
    "# Page 15718â€“15729, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0169102d-89ab-491e-98a3-63d871d868eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, OrderedDict\n",
    "class OrderedCounter(Counter, OrderedDict):\n",
    "    \"\"\"Counter that remembers the order elements are first encountered.\"\"\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '%s(%r)' % (self.__class__.__name__, OrderedDict(self))\n",
    "\n",
    "    def __reduce__(self):\n",
    "        return self.__class__, (OrderedDict(self),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28ca461d-ee6c-4dce-98e6-bea1b9f78ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "with open(os.path.join(DATA_PATH, 'cub/text_trainvalclasses.txt'), 'r') as file:\n",
    "    text = file.read()\n",
    "    sentences = sent_tokenize(text)\n",
    "\n",
    "occ_register = OrderedCounter() # For counting the occurrance and calc. weights\n",
    "texts = [] # For embedding\n",
    "for i, line in enumerate(sentences):\n",
    "    words = word_tokenize(line)\n",
    "    texts.append(words)\n",
    "    occ_register.update(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "589715fa-d6b8-46ba-842a-5cbe2ebdfdd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5586509, 15113120)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FastText embedding\n",
    "model = FastText(vector_size=300, window=5, min_count=3)\n",
    "model.build_vocab(corpus_iterable=texts)\n",
    "model.train(corpus_iterable=texts, total_examples=len(texts), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "792f77cb-4aba-426f-a836-b80854cc30a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_PATH, 'cub/oc:3_msl:32/cub.vocab'), 'rb') as file:\n",
    "    vocab = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "321fe86e-197d-4c62-9073-2116fd1e97ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output embedding\n",
    "i2w = vocab['i2w']\n",
    "base = np.ones((300,), dtype=np.float32)\n",
    "emb = [base * (i - 1) for i in range(3)]\n",
    "for word in list(i2w.values())[3:]:\n",
    "    emb.append(model.wv[word])\n",
    "\n",
    "emb = np.array(emb)\n",
    "with open(os.path.join(DATA_PATH, 'cub/oc:3_msl:32/cub.emb'), 'wb') as file:\n",
    "    pickle.dump(emb, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b24a833e-2b23-444f-8da7-1230b7a75b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output weights\n",
    "a = 1e-3\n",
    "w2i = vocab['w2i']\n",
    "weights = np.zeros(len(w2i))\n",
    "total_occ = sum(list(occ_register.values()))\n",
    "exc_occ = 0\n",
    "for w, occ in occ_register.items():\n",
    "    if w in w2i.keys():\n",
    "        weights[w2i[w]] = a / (a + occ / total_occ)\n",
    "    else:\n",
    "        exc_occ += occ\n",
    "weights[0] = a / (a + exc_occ / total_occ)\n",
    "\n",
    "with open(os.path.join(DATA_PATH, 'cub/oc:3_msl:32/cub.weights'), 'wb') as file:\n",
    "    pickle.dump(weights, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbf6c34e-626d-4b19-b202-d72c399f2212",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = lambda data: torch.Tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee904f38-4d05-4fb7-b4db-eff0f06b4965",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31018873-e160-4b82-bc2b-da72a83b61ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUB_train = CUB(DATA_PATH, DATA_PATH, 'train', device, tx, return_idx=False)\n",
    "CUB_test = CUB(DATA_PATH, DATA_PATH, 'test', device, tx, return_idx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f53ef38b-79b9-46b5-91c9-49f20f68879c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1590, 32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size, txt_len = CUB_train.CUBtxt.vocab_size, CUB_train.CUBtxt.max_sequence_length\n",
    "vocab_size, txt_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cc22ab4-5ac9-4cd0-9a08-3fd9217c0b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(692, 230)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "train_loader = torch.utils.data.DataLoader(CUB_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(CUB_test, batch_size=batch_size, shuffle=True)\n",
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72549bf1-688b-47e6-b7d3-8345c1198cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUB_train.CUBtxt.eos_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f6c655c-26b3-4649-980f-3490b54bd3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_PATH, 'cub/oc:3_msl:32/cub.emb'), 'rb') as file:\n",
    "    emb = pickle.load(file)\n",
    "with open(os.path.join(DATA_PATH, 'cub/oc:3_msl:32/cub.weights'), 'rb') as file:\n",
    "    weights = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1549db4f-8566-451f-8300-45087af177e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_txt_data = torch.cat([d[1] for d in train_loader]).detach().cpu().numpy().astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1080271f-1326-43a4-9a4b-8860bbaef662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88548, 300)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = np.zeros((full_txt_data.shape[0], emb.shape[1]))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "492f04ea-cff7-4527-a677-2809e4f96683",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_img_data = torch.cat([d[0] for d in train_loader]).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67ea0727-71c7-4419-9bb9-5e5c84fc3ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_emb(full_txt_data, emb, weights, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78ba4b7e-8831-440d-815d-67f052deebe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = torch.tensor(output).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13a5c1df-3899-48e0-aae4-a7e6439c2e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, V = torch.svd(output - output.mean(axis=0))\n",
    "v = V[:, 0].unsqueeze(-1)\n",
    "PC = v.mm(v.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f87ad785-a6f7-4dc9-b5a5-37f8f22f0f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(PC, 'sentence_emb_PC2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b11cb346-986f-4381-aeff-5e379b880c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_pca = pca_transform(output, PC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e9847f3-bf79-43cb-8a83-f7c49a6b3756",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(sent_pca, 'true_data_sent_embedding2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "631236c0-2894-4a5f-99dc-cd5ace91fd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, V = torch.svd(full_img_data - full_img_data.mean(axis=0))\n",
    "v = V[:, 0].unsqueeze(-1)\n",
    "PC = v.mm(v.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41d0eb7a-f4ff-47be-813c-8d85cc8d3a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(PC, 'image_PC2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b941821-34c9-4623-b751-74479ac126d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pca = pca_transform(full_img_data, PC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "00dabdf3-1766-4d49-8c74-f91c1a99bed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(img_pca, 'true_data_img_feature2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446a387f-d859-4b03-9f76-dc93b7b3b7b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
