{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ad62d0b-55f6-4e07-b67b-fcdbfa531d3f",
   "metadata": {},
   "source": [
    "## FastText Embedding for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b063a32d-715e-4d2d-819e-79e33646f622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07e4985-a2e3-4fca-94e3-297a5bd9544c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code is adapted from https://github.com/iffsid/mmvae, the repository for the work\n",
    "# Y. Shi, N. Siddharth, B. Paige and PHS. Torr.\n",
    "# Variational Mixture-of-Experts Autoencoders for Multi-Modal Deep Generative Models.\n",
    "# In Proceedings of the 33rd International Conference on Neural Information Processing Systems,\n",
    "# Page 15718â€“15729, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0169102d-89ab-491e-98a3-63d871d868eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, OrderedDict\n",
    "class OrderedCounter(Counter, OrderedDict):\n",
    "    \"\"\"Counter that remembers the order elements are first encountered.\"\"\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '%s(%r)' % (self.__class__.__name__, OrderedDict(self))\n",
    "\n",
    "    def __reduce__(self):\n",
    "        return self.__class__, (OrderedDict(self),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ca461d-ee6c-4dce-98e6-bea1b9f78ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "with open(os.path.join(DATA_PATH, 'cub/text_trainvalclasses.txt'), 'r') as file:\n",
    "    text = file.read()\n",
    "    sentences = sent_tokenize(text)\n",
    "\n",
    "occ_register = OrderedCounter() # For counting the occurrance and calc. weights\n",
    "texts = [] # For embedding\n",
    "for i, line in enumerate(sentences):\n",
    "    words = word_tokenize(line)\n",
    "    texts.append(words)\n",
    "    occ_register.update(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589715fa-d6b8-46ba-842a-5cbe2ebdfdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FastText embedding\n",
    "model = FastText(vector_size=300, window=3, min_count=3)\n",
    "model.build_vocab(corpus_iterable=texts)\n",
    "model.train(corpus_iterable=texts, total_examples=len(texts), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792f77cb-4aba-426f-a836-b80854cc30a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_PATH, 'cub/oc:3_msl:32/cub.vocab'), 'rb') as file:\n",
    "    vocab = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321fe86e-197d-4c62-9073-2116fd1e97ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output embedding\n",
    "i2w = vocab['i2w']\n",
    "base = np.ones((300,), dtype=np.float32)\n",
    "emb = [base * (i - 1) for i in range(3)]\n",
    "for word in list(i2w.values())[3:]:\n",
    "    emb.append(model.wv[word])\n",
    "\n",
    "emb = np.array(emb)\n",
    "with open(os.path.join(DATA_PATH, 'cub/oc:3_msl:32/cub.emb'), 'wb') as file:\n",
    "    pickle.dump(emb, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24a833e-2b23-444f-8da7-1230b7a75b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output weights\n",
    "a = 1e-3\n",
    "w2i = vocab['w2i']\n",
    "weights = np.zeros(len(w2i))\n",
    "total_occ = sum(list(occ_register.values()))\n",
    "exc_occ = 0\n",
    "for w, occ in occ_register.items():\n",
    "    if w in w2i.keys():\n",
    "        weights[w2i[w]] = a / (a + occ / total_occ)\n",
    "    else:\n",
    "        exc_occ += occ\n",
    "weights[0] = a / (a + exc_occ / total_occ)\n",
    "\n",
    "with open(os.path.join(DATA_PATH, 'cub/oc:3_msl:32/cub.weights'), 'wb') as file:\n",
    "    pickle.dump(weights, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6c655c-26b3-4649-980f-3490b54bd3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_PATH, 'cub/oc:3_msl:32/cub.emb'), 'rb') as file:\n",
    "    emb = pickle.load(file)\n",
    "with open(os.path.join(DATA_PATH, 'cub/oc:3_msl:32/cub.weights'), 'rb') as file:\n",
    "    emb = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97c81c1-97a2-439c-a2b2-e881c4b80d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(txt_train, batch_size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1549db4f-8566-451f-8300-45087af177e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_loader:\n",
    "    print(data[0][0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828c74be-63a2-40fa-aff2-a9b8a2002e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
