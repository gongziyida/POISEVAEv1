{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31b49d1a-2833-46a5-b8f3-c43ae1c123e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F  # activation function\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import poisevae\n",
    "\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 20\n",
    "plt.rcParams['font.weight'] = 'normal'\n",
    "plt.rcParams['mathtext.fontset'] = 'cm'\n",
    "plt.rcParams['text.usetex'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2617bd66-2c15-404b-9b8c-31a9b3a2e3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_PATH = os.path.expanduser('~')\n",
    "DATA_PATH = os.path.join(HOME_PATH, 'Datasets/CUB/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45980a9b-ce22-4cd1-b8a7-634da8c811c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncImg(nn.Module):\n",
    "    def __init__(self, latent_dim, input_dim=2048):\n",
    "        super(EncImg, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        n = (input_dim, 1024, 512, 256)\n",
    "        li = []\n",
    "        for i in range(len(n)-1):\n",
    "            li += [nn.Linear(n[i], n[i+1]), nn.ELU(inplace=True)]\n",
    "        self.enc = nn.Sequential(*li)\n",
    "        self.enc_mu = nn.Linear(256, latent_dim)\n",
    "        self.enc_var = nn.Linear(256, latent_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.enc(x)\n",
    "        mu = self.enc_mu(x)\n",
    "        log_var = self.enc_var(x)\n",
    "        return mu, log_var\n",
    "\n",
    "class DecImg(nn.Module):\n",
    "    def __init__(self, latent_dim, output_dim=2048):\n",
    "        super(DecImg, self).__init__()  \n",
    "        self.latent_dim = latent_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        n = (output_dim, 1024, 512, 256)\n",
    "        li = [nn.Linear(latent_dim, 256)]\n",
    "        for i in range(len(n)-1, 0, -1):\n",
    "            li += [nn.ELU(inplace=True), nn.Linear(n[i], n[i-1])]\n",
    "        self.dec = nn.Sequential(*li)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        return self.dec(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27158ccf-6906-4321-ad56-34a932777d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncTxt(nn.Module):\n",
    "    def __init__(self, vocab_size, latent_dim, emb_dim=128):\n",
    "        super(EncTxt, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.latent_dim = latent_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        \n",
    "        # 0 is for the excluded words and does not contribute to gradient\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "\n",
    "        n_channels = (1, 32, 64, 128, 256, 512)\n",
    "        kernels = (4, 4, 4, (1, 4), (1, 4))\n",
    "        strides = (2, 2, 2, (1, 2), (1, 2))\n",
    "        paddings = (1, 1, 1, (0, 1), (0, 1))\n",
    "        li = []\n",
    "        for i, (n, k, s, p) in enumerate(zip(n_channels[1:], kernels, strides, paddings), 1):\n",
    "            li += [nn.Conv2d(n_channels[i-1], n, kernel_size=k, stride=s, padding=p), \n",
    "                   nn.BatchNorm2d(n), nn.ReLU(inplace=True)]\n",
    "            \n",
    "        self.enc = nn.Sequential(*li)\n",
    "        self.enc_mu = nn.Conv2d(512, latent_dim, kernel_size=4, stride=1, padding=0)\n",
    "        self.enc_var = nn.Conv2d(512, latent_dim, kernel_size=4, stride=1, padding=0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.emb(x.long()).unsqueeze(1) # add channel dim\n",
    "        x = self.enc(x)\n",
    "        mu = self.enc_mu(x).squeeze()\n",
    "        log_var = self.enc_var(x).squeeze()\n",
    "        return mu, log_var\n",
    "\n",
    "class DecTxt(nn.Module):\n",
    "    def __init__(self, vocab_size, latent_dim, emb_dim=128, txt_len=32):\n",
    "        super(DecTxt, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.latent_dim = latent_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.txt_len = txt_len\n",
    "        \n",
    "        n_channels = (1, 32, 64, 128, 256, 512, latent_dim)\n",
    "        kernels = (4, 4, 4, (1, 4), (1, 4), 4)\n",
    "        strides = (2, 2, 2, (1, 2), (1, 2), 1)\n",
    "        paddings = (1, 1, 1, (0, 1), (0, 1), 0)\n",
    "        li = []\n",
    "        for i, (n, k, s, p) in enumerate(zip(n_channels[1:], kernels, strides, paddings), 1):\n",
    "            li = [nn.ConvTranspose2d(n, n_channels[i-1], kernel_size=k, stride=s, padding=p), \n",
    "                  nn.BatchNorm2d(n_channels[i-1]), nn.ReLU(inplace=True)] + li\n",
    "            \n",
    "        # No batchnorm at the first and last block\n",
    "        del li[-2]\n",
    "        del li[1]\n",
    "        self.dec = nn.Sequential(*li)\n",
    "        self.anti_emb = nn.Linear(emb_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, z, argmax=False):\n",
    "        z = self.dec(z)\n",
    "        z = self.anti_emb(z.view(-1, self.emb_dim))\n",
    "        z = z.view(-1, self.txt_len, self.vocab_size) # batch x txt len x vocab size\n",
    "        if argmax:\n",
    "            z = z.argmax(-1).float()\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27f0bb9d-30b5-4e79-be48-e46ee2b8a8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = lambda data: torch.Tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cba9b1ec-5083-4a19-affa-e0720b60d3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0513a4f-e792-4606-a624-478562027aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUB_train = poisevae.utils.CUB(DATA_PATH, DATA_PATH, 'train', device, tx, return_idx=False)\n",
    "CUB_test = poisevae.utils.CUB(DATA_PATH, DATA_PATH, 'test', device, tx, return_idx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88947a74-5dfc-4181-a9ce-c0dbdd9ae419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1590, 32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size, txt_len = CUB_train.CUBtxt.vocab_size, CUB_train.CUBtxt.max_sequence_length\n",
    "vocab_size, txt_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e601a8c-e46f-4cf0-9985-f2431788ec5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(692, 230)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "train_loader = torch.utils.data.DataLoader(CUB_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(CUB_test, batch_size=batch_size, shuffle=True)\n",
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a68120dc-2f9e-49b1-8dfc-579032c915b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_img = EncImg(128).to(device)\n",
    "dec_img = DecImg(128).to(device)\n",
    "enc_txt = EncTxt(vocab_size, 128).to(device)\n",
    "dec_txt = DecTxt(vocab_size, 128).to(device)\n",
    "\n",
    "def CELoss(input, target):\n",
    "    batch_size = target.shape[0]\n",
    "    input, target = input.view(-1, vocab_size), target.view(-1).to(torch.long)\n",
    "    loss = nn.functional.cross_entropy(input, target, reduction='sum') #/ batch_size\n",
    "    return loss\n",
    "    \n",
    "def MSELoss(input, target):\n",
    "    loss = nn.functional.mse_loss(input, target, reduction='sum') #/ batch_size\n",
    "    return loss / 10\n",
    "    \n",
    "def MAELoss(input, target):\n",
    "    loss = nn.functional.l1_loss(input, target, reduction='sum') #/ batch_size\n",
    "    return loss / 10\n",
    "    \n",
    "vae = poisevae.POISEVAE([enc_img, enc_txt], [dec_img, dec_txt], [MAELoss, CELoss], \n",
    "                        latent_dims=[128, (128, 1, 1)]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "101efaf3-fe96-4c0c-96d0-2bc826f15cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in vae.named_parameters():\n",
    "#     print(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "292dc208-4258-4108-ae4d-80d954ab45dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(vae.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12663d4c-8f82-4b21-bed4-67044e7ea7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = os.path.join(HOME_PATH, 'Datasets/MNIST_SVHN_train_results/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c8f75ff-8b35-4e7a-b25d-324a43c1040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "# try:\n",
    "#     vae, optimizer, epoch = poisevae.utils.load_checkpoint(vae, optimizer, sorted(glob.glob(PATH + 'train*.pt'))[-1])\n",
    "# except:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bee31f58-a928-443d-8cc9-a5d85d0b0216",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 50\n",
      "Train Loss: 107.1283\n",
      "\tRec: 48.3103, 60.5953\n",
      "\tKLD Loss -1.7773\n",
      "Test Loss: 97.1767\n",
      "\tRec: 47.2895, 52.0703\n",
      "\tKLD Loss -2.1830\n",
      "Epoch 2 of 50\n",
      "Train Loss: 94.6046\n",
      "\tRec: 46.4041, 50.0149\n",
      "\tKLD Loss -1.8144\n",
      "Test Loss: 92.5723\n",
      "\tRec: 45.9740, 47.7534\n",
      "\tKLD Loss -1.1551\n",
      "Epoch 3 of 50\n",
      "Train Loss: 90.5610\n",
      "\tRec: 45.7853, 45.6732\n",
      "\tKLD Loss -0.8975\n",
      "Test Loss: 89.2368\n",
      "\tRec: 45.7290, 44.0571\n",
      "\tKLD Loss -0.5493\n",
      "Epoch 4 of 50\n",
      "Train Loss: 87.5158\n",
      "\tRec: 45.2783, 42.8073\n",
      "\tKLD Loss -0.5697\n",
      "Test Loss: 85.6747\n",
      "\tRec: 45.1160, 41.6197\n",
      "\tKLD Loss -1.0609\n",
      "Epoch 5 of 50\n",
      "Train Loss: 85.0444\n",
      "\tRec: 44.7059, 40.9578\n",
      "\tKLD Loss -0.6193\n",
      "Test Loss: 85.4553\n",
      "\tRec: 44.8308, 40.4920\n",
      "\tKLD Loss 0.1325\n",
      "Epoch 6 of 50\n",
      "Train Loss: 83.4326\n",
      "\tRec: 44.3686, 39.5839\n",
      "\tKLD Loss -0.5200\n",
      "Test Loss: 83.4635\n",
      "\tRec: 44.4021, 39.2754\n",
      "\tKLD Loss -0.2141\n",
      "Epoch 7 of 50\n",
      "Train Loss: 81.9734\n",
      "\tRec: 44.1303, 38.4123\n",
      "\tKLD Loss -0.5691\n",
      "Test Loss: 81.9268\n",
      "\tRec: 44.2794, 38.3196\n",
      "\tKLD Loss -0.6721\n",
      "Epoch 8 of 50\n",
      "Train Loss: 80.8848\n",
      "\tRec: 43.9131, 37.4362\n",
      "\tKLD Loss -0.4646\n",
      "Test Loss: 81.2554\n",
      "\tRec: 43.9212, 37.4872\n",
      "\tKLD Loss -0.1529\n",
      "Epoch 9 of 50\n",
      "Train Loss: 79.8270\n",
      "\tRec: 43.6338, 36.5690\n",
      "\tKLD Loss -0.3759\n",
      "Test Loss: 79.0194\n",
      "\tRec: 43.7019, 36.5565\n",
      "\tKLD Loss -1.2390\n",
      "Epoch 10 of 50\n",
      "Train Loss: 78.8064\n",
      "\tRec: 43.4459, 35.8580\n",
      "\tKLD Loss -0.4976\n",
      "Test Loss: 78.9441\n",
      "\tRec: 43.5272, 36.1874\n",
      "\tKLD Loss -0.7705\n",
      "Epoch 11 of 50\n",
      "Train Loss: 78.0933\n",
      "\tRec: 43.2905, 35.2357\n",
      "\tKLD Loss -0.4329\n",
      "Test Loss: 78.4384\n",
      "\tRec: 43.4744, 35.5639\n",
      "\tKLD Loss -0.6000\n",
      "Epoch 12 of 50\n",
      "Train Loss: 77.3653\n",
      "\tRec: 43.1741, 34.6040\n",
      "\tKLD Loss -0.4128\n",
      "Test Loss: 77.7406\n",
      "\tRec: 43.3034, 35.2011\n",
      "\tKLD Loss -0.7638\n",
      "Epoch 13 of 50\n",
      "Train Loss: 76.7888\n",
      "\tRec: 43.0870, 34.0588\n",
      "\tKLD Loss -0.3570\n",
      "Test Loss: 78.1230\n",
      "\tRec: 43.2772, 34.5941\n",
      "\tKLD Loss 0.2516\n",
      "Epoch 14 of 50\n",
      "Train Loss: 76.2705\n",
      "\tRec: 42.9876, 33.6062\n",
      "\tKLD Loss -0.3234\n",
      "Test Loss: 76.5036\n",
      "\tRec: 43.2990, 34.1810\n",
      "\tKLD Loss -0.9764\n",
      "Epoch 15 of 50\n",
      "Train Loss: 75.6933\n",
      "\tRec: 42.9298, 33.1316\n",
      "\tKLD Loss -0.3682\n",
      "Test Loss: 77.0195\n",
      "\tRec: 43.2079, 33.8283\n",
      "\tKLD Loss -0.0166\n",
      "Epoch 16 of 50\n",
      "Train Loss: 75.2138\n",
      "\tRec: 42.8560, 32.7545\n",
      "\tKLD Loss -0.3967\n",
      "Test Loss: 76.3475\n",
      "\tRec: 43.2964, 33.5444\n",
      "\tKLD Loss -0.4933\n",
      "Epoch 17 of 50\n",
      "Train Loss: 74.7072\n",
      "\tRec: 42.8046, 32.3744\n",
      "\tKLD Loss -0.4719\n",
      "Test Loss: 76.3453\n",
      "\tRec: 43.1163, 33.1984\n",
      "\tKLD Loss 0.0306\n",
      "Epoch 18 of 50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_252520/2846302327.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1} of {epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_epoch_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoisevae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_epoch_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoisevae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_latents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/vae_project/POISEVAE/poisevae/utils/functions.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, joint_dataloader, optimizer, epoch, record_idx, return_latents, progress_bar, device, dtype)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mrunning_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "test_loss = []\n",
    "epochs = 50 + epoch\n",
    "for epoch in range(epoch, epochs):\n",
    "    print(f\"Epoch {epoch+1} of {epochs}\")\n",
    "    train_epoch_losses = poisevae.utils.train(vae, train_loader, optimizer, epoch)\n",
    "    train_loss.append(train_epoch_losses)\n",
    "    ret = poisevae.utils.test(vae, test_loader, epoch, return_latents=True)\n",
    "    test_epoch_losses, latent_info = ret[:4], ret[-1]\n",
    "    test_loss.append(test_epoch_losses)\n",
    "    print(f\"Train Loss: %.4f\\n\\tRec: %.4f, %.4f\\n\\tKLD Loss %.4f\" % train_epoch_losses)\n",
    "    print(f\"Test Loss: %.4f\\n\\tRec: %.4f, %.4f\\n\\tKLD Loss %.4f\" % test_epoch_losses)\n",
    "    if (epoch+1) % 10 == 0 and epoch > 0:\n",
    "        poisevae.utils.save_checkpoint(vae, optimizer, PATH + 'training_%d.pt' % (epoch+1), epoch+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a00c51-cd1d-45aa-bf15-09c0f29533e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = np.array(train_loss).T\n",
    "test_loss = np.array(test_loss).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ea1deb-19d1-49c9-b6ce-37b5594a2919",
   "metadata": {},
   "outputs": [],
   "source": [
    "poisevae.utils.save_latent_info(latent_info, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d054fd-d2f9-4a81-a0d3-72320025e061",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b826be-cabd-4923-a7ec-45e67bd94705",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_loss[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7c01ac-318b-461e-8ba0-608a360e6359",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, sharex='all', sharey='all', figsize=(9, 4))\n",
    "\n",
    "for i, label in enumerate(('Total', 'Rec1', 'Rec2', 'KLD')):\n",
    "    ax[0].plot(train_loss[i], label=label)\n",
    "    ax[1].plot(test_loss[i], label=label)\n",
    "ax[0].set_title('Train')\n",
    "ax[1].set_title('Validation')\n",
    "fig.legend(*ax[0].get_legend_handles_labels(), fontsize='small')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71549c9c-3cc9-41ae-aeaf-f32da3946ffb",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32cec65-c3da-4c59-bd16-2cd2275a9a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code is adapted from https://github.com/iffsid/mmvae, the repository for the work\n",
    "# Y. Shi, N. Siddharth, B. Paige and PHS. Torr.\n",
    "# Variational Mixture-of-Experts Autoencoders for Multi-Modal Deep Generative Models.\n",
    "# In Proceedings of the 33rd International Conference on Neural Information Processing Systems,\n",
    "# Page 15718â€“15729, 2019\n",
    "\n",
    "def pdist(sample_1, sample_2, eps=1e-8):\n",
    "    \"\"\"Compute the matrix of all squared pairwise distances. Code\n",
    "    adapted from the torch-two-sample library (added batching).\n",
    "    You can find the original implementation of this function here:\n",
    "    https://github.com/josipd/torch-two-sample/blob/master/torch_two_sample/util.py\n",
    "    Arguments\n",
    "    ---------\n",
    "    sample_1 : torch.Tensor or Variable\n",
    "        The first sample, should be of shape ``(batch_size, n_1, d)``.\n",
    "    sample_2 : torch.Tensor or Variable\n",
    "        The second sample, should be of shape ``(batch_size, n_2, d)``.\n",
    "    norm : float\n",
    "        The l_p norm to be used.\n",
    "    batched : bool\n",
    "        whether data is batched\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor or Variable\n",
    "        Matrix of shape (batch_size, n_1, n_2). The [i, j]-th entry is equal to\n",
    "        ``|| sample_1[i, :] - sample_2[j, :] ||_p``.\"\"\"\n",
    "    if len(sample_1.shape) == 2:\n",
    "        sample_1, sample_2 = sample_1.unsqueeze(0), sample_2.unsqueeze(0)\n",
    "    B, n_1, n_2 = sample_1.size(0), sample_1.size(1), sample_2.size(1)\n",
    "    norms_1 = torch.sum(sample_1 ** 2, dim=-1, keepdim=True)\n",
    "    norms_2 = torch.sum(sample_2 ** 2, dim=-1, keepdim=True)\n",
    "    norms = (norms_1.expand(B, n_1, n_2)\n",
    "             + norms_2.transpose(1, 2).expand(B, n_1, n_2))\n",
    "    distances_squared = norms - 2 * sample_1.matmul(sample_2.transpose(1, 2))\n",
    "    return torch.sqrt(eps + torch.abs(distances_squared)).squeeze()  # batch x K x latent\n",
    "\n",
    "\n",
    "def NN_lookup(emb_h, emb):\n",
    "    dist = pdist(emb.to(emb_h.device), emb_h)\n",
    "    return dist, dist.argmin(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117dcbe6-b309-44cd-8994-27a6f1888abe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vae, optimizer, epoch = poisevae.utils.load_checkpoint(vae, optimizer, sorted(glob.glob(PATH + 'train*.pt'))[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4df4403-71d7-466c-9228-7a2a95b7c8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26711b10-747c-4df5-a4a5-9ba9ec35039c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for i, (img, txt, idx) in enumerate(test_loader):\n",
    "        results = vae([img.to(device), txt.to(device)])\n",
    "        dist, idx_h = NN_lookup(results['x_rec'][0], img)\n",
    "        # dist, idx_h = NN_lookup(results['x_rec'][0], img)\n",
    "        imgs_h = [CUB_test.CUBimg.dataset[int(idx[j]) // 10][0] for j in idx_h]\n",
    "        imgs = [CUB_test.CUBimg.dataset[int(j) // 10][0] for j in idx]\n",
    "        txts = [CUB_test.CUBtxt.data[str(int(j))] for j in idx]\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29b620c-e362-4afc-82e8-5ae452805d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = min(len(imgs_h), 20)\n",
    "fig, ax = plt.subplots(nrows=2, ncols=ncols, figsize=(15, 1.5))\n",
    "for i, aux in enumerate(zip(imgs, imgs_h)):\n",
    "    if i >= ncols:\n",
    "        break\n",
    "    for j, im in enumerate(aux):\n",
    "        ax[j, i].imshow(im.permute(1, 2, 0))\n",
    "        ax[j, i].set_xticks([])\n",
    "        ax[j, i].set_yticks([])\n",
    "ax[1, 0].set_ylabel('Rec', fontsize=24)\n",
    "fig.tight_layout(pad=0)\n",
    "fig.savefig(PATH + 'CUBImgRec.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4bfe12-172d-49bc-a943-bac8910cecbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = min(len(imgs_h), 20)\n",
    "nrows = 2 * int(np.floor(len(imgs_h) / 20))\n",
    "fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(15, 1.5*nrows/2))\n",
    "for i, aux in enumerate(zip(imgs, imgs_h)):\n",
    "    if i >= nrows / 2 * 20:\n",
    "        break\n",
    "    for j, im in enumerate(aux):\n",
    "        ax[j+i//20*2, i%20].imshow(im.permute(1, 2, 0))\n",
    "        ax[j+i//20*2, i%20].set_xticks([])\n",
    "        ax[j+i//20*2, i%20].set_yticks([])\n",
    "    ax[1+i//20*2, 0].set_ylabel('Rec', fontsize=24)\n",
    "fig.tight_layout(pad=0)\n",
    "fig.savefig(PATH + 'CUBImgRecExtra.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e7b6d3-1eac-4ba3-b4af-91ca83c1e5ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sents_h = []\n",
    "sents_emb = results['x_rec'][1].argmax(-1)\n",
    "for sent_emb in sents_emb:\n",
    "    sent_h = []\n",
    "    for j in sent_emb:\n",
    "        char = CUB_test.CUBtxt.i2w[str(int(j.item()))]\n",
    "        if char == '<eos>':\n",
    "            break\n",
    "        sent_h.append(char)\n",
    "    sents_h.append(' '.join(sent_h))\n",
    "\n",
    "sents = []\n",
    "for i, sent_h in enumerate(sents_h):\n",
    "    sent = []\n",
    "    for char in txts[i]['tok']:\n",
    "        if char == '<eos>':\n",
    "            break\n",
    "        sent.append(char)\n",
    "    sents.append(' '.join(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9b70cf-4dd7-4ef8-abc7-eff3c303e04b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for sent, sent_h in zip(sents, sents_h):\n",
    "    print('     ', sent)\n",
    "    print('Rec: ', sent_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2985b9-13c3-4ed7-82b2-602cc1d1d5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH + 'CUBTxtRec.txt', 'w') as file:\n",
    "    for sent, sent_h in zip(sents, sents_h):\n",
    "        file.write('Ref: ' + sent + '\\n')\n",
    "        file.write('Rec: ' + sent_h + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8cfe7e-5d06-4134-bdfb-0076ac3039f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
