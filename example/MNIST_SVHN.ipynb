{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "155ea9f1-702b-434e-8a3f-4d10aa0869d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F  # activation function\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Normal, Laplace\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import poisevae\n",
    "from poisevae.datasets import MNIST_SVHN\n",
    "\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 20\n",
    "plt.rcParams['font.weight'] = 'normal'\n",
    "plt.rcParams['mathtext.fontset'] = 'cm'\n",
    "plt.rcParams['text.usetex'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "200baa32-4b85-4438-b679-6cfd7b163970",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_PATH = os.path.expanduser('~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21b145c8-abc4-4a4e-878c-778733cc6a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncMNIST(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(EncMNIST, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.dim_MNIST = 28 * 28\n",
    "\n",
    "        self.enc1 = nn.Linear(self.dim_MNIST, 400)\n",
    "        self.enc_mu = nn.Linear(400, latent_dim)\n",
    "        self.enc_var = nn.Linear(400, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.enc1(x))\n",
    "        mu = self.enc_mu(x)\n",
    "        log_var = self.enc_var(x)\n",
    "        return mu, log_var\n",
    "\n",
    "class DecMNIST(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(DecMNIST, self).__init__()  \n",
    "        self.latent_dim = latent_dim\n",
    "        self.dim_MNIST   = 28 * 28\n",
    "        \n",
    "        self.dec = nn.Sequential(nn.Linear(self.latent_dim, 400), \n",
    "                                 nn.ReLU(inplace=True), \n",
    "                                 nn.Linear(400, self.dim_MNIST), \n",
    "                                 nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, z):\n",
    "        return self.dec(z), torch.tensor(0.75).to(z.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fe577f9-8515-4229-9659-6f14f3f37b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncSVHN(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(EncSVHN, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        n_channels = (3, 32, 64, 128)\n",
    "        kernels = (4, 4, 4)\n",
    "        strides = (2, 2, 2)\n",
    "        paddings = (1, 1, 1)\n",
    "        li = []\n",
    "        for i, (n, k, s, p) in enumerate(zip(n_channels[1:], kernels, strides, paddings), 1):\n",
    "            li += [nn.Conv2d(n_channels[i-1], n, kernel_size=k, stride=s, padding=p), \n",
    "                   nn.ReLU(inplace=True)]\n",
    "            \n",
    "        self.enc = nn.Sequential(*li)\n",
    "        self.enc_mu = nn.Conv2d(in_channels=128, out_channels=latent_dim, \n",
    "                                kernel_size=4, stride=1, padding=0)\n",
    "        self.enc_var = nn.Conv2d(in_channels=128, out_channels=latent_dim, \n",
    "                                 kernel_size=4, stride=1, padding=0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.enc(x)\n",
    "        # Be careful not to squeeze the batch dimension if batch size = 1\n",
    "        mu = self.enc_mu(x).squeeze(3).squeeze(2)\n",
    "        log_var = self.enc_var(x).squeeze(3).squeeze(2)\n",
    "        return mu, log_var\n",
    "    \n",
    "class DecSVHN(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(DecSVHN, self).__init__()  \n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        n_channels = (latent_dim, 128, 64, 32, 3)\n",
    "        kernels = (4, 4, 4, 4)\n",
    "        strides = (1, 2, 2, 2)\n",
    "        paddings = (0, 1, 1, 1)\n",
    "        li = []\n",
    "        for i, (n, k, s, p) in enumerate(zip(n_channels[1:], kernels, strides, paddings), 1):\n",
    "            li += [nn.ConvTranspose2d(n_channels[i-1], n, kernel_size=k, stride=s, padding=p), \n",
    "                   nn.ReLU(inplace=True)]\n",
    "        li[-1] = nn.Sigmoid()\n",
    "        \n",
    "        self.dec = nn.Sequential(*li)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        return self.dec(z), torch.tensor(0.75).to(z.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cba9b1ec-5083-4a19-affa-e0720b60d3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc4383bd-e443-49a6-afe9-1ffcc2a8f016",
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_PATH = os.path.join(HOME_PATH, 'Datasets/MNIST/%s.pt')\n",
    "SVHN_PATH = os.path.join(HOME_PATH, 'Datasets/SVHN/%s_32x32.mat')\n",
    "MNIST_SAMPLER_PATH = os.path.join(HOME_PATH, 'Datasets/MNIST/MNIST_%s_idx.pt')\n",
    "SVHN_SAMPLER_PATH = os.path.join(HOME_PATH, 'Datasets/SVHN/SVHN_%s_idx.pt')\n",
    "\n",
    "joint_dataset_train = MNIST_SVHN(mnist_pt_path=MNIST_PATH % 'train', svhn_mat_path=SVHN_PATH % 'train')\n",
    "joint_dataset_test = MNIST_SVHN(mnist_pt_path=MNIST_PATH % 'test', svhn_mat_path=SVHN_PATH % 'test')\n",
    "\n",
    "# joint_dataset_train = MNIST_SVHN(mnist_pt_path=MNIST_PATH % 'train', svhn_mat_path=SVHN_PATH % 'train', \n",
    "#                                 sampler_mnist=torch.load(MNIST_SAMPLER_PATH % 'train'), \n",
    "#                                 sampler_svhn=torch.load(SVHN_SAMPLER_PATH % 'train'))\n",
    "# joint_dataset_test = MNIST_SVHN(mnist_pt_path=MNIST_PATH % 'test', svhn_mat_path=SVHN_PATH % 'test',\n",
    "#                                sampler_mnist=torch.load(MNIST_SAMPLER_PATH % 'test'), \n",
    "#                                sampler_svhn=torch.load(SVHN_SAMPLER_PATH % 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e601a8c-e46f-4cf0-9985-f2431788ec5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(468, 78)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "train_loader = torch.utils.data.DataLoader(joint_dataset_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(joint_dataset_test, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f35b8b67-1ad8-4302-a8c3-0cc35a0484b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_missing(data):\n",
    "    # data: (mnist, svhn, label, label)\n",
    "    rand_num = random.random()\n",
    "    if rand_num < 0.2: # Send both\n",
    "        return data\n",
    "    elif rand_num > 0.6: # Send SVHN only\n",
    "        return None, *data[1:]\n",
    "    else: # Send MNIST only\n",
    "        return data[0], None, *data[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a68120dc-2f9e-49b1-8dfc-579032c915b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat1, lat2 = 16, 24\n",
    "enc_mnist = EncMNIST(lat1).to(device)\n",
    "dec_mnist = DecMNIST(lat1).to(device)\n",
    "enc_svhn = EncSVHN(lat2).to(device)\n",
    "dec_svhn = DecSVHN(lat2).to(device)\n",
    "\n",
    "# def MSELoss(input, target):\n",
    "#     loss = nn.functional.mse_loss(input, target, reduction='sum') #/ batch_size\n",
    "#     return loss\n",
    "    \n",
    "# def MAELoss(input, target):\n",
    "#     loss = nn.functional.l1_loss(input, target, reduction='sum') #/ batch_size\n",
    "#     return loss\n",
    "    \n",
    "vae = poisevae.POISEVAE([enc_mnist, enc_svhn], [dec_mnist, dec_svhn], likelihoods=[Laplace, Laplace],\n",
    "                        latent_dims=[lat1, (lat2, 1, 1)], batch_size=batch_size, mask_missing=mask_missing).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ccb1dfb-d583-4edb-b017-ae9c646567af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in vae.named_parameters():\n",
    "#     print(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "292dc208-4258-4108-ae4d-80d954ab45dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(vae.parameters(), lr=8e-4, amsgrad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26b8485c-96a2-4a2c-a837-a479b245fdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = os.path.join('runs/MNIST_SVHN', datetime.now().strftime('%y%m%d%H%M'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c8f75ff-8b35-4e7a-b25d-324a43c1040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "# try:\n",
    "#     vae, optimizer, epoch = load_checkpoint(vae, optimizer, sorted(glob.glob(PATH + 'train*.pt'))[-1])\n",
    "# except:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee965133-67c9-4162-8494-30205c86be54",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c687039a-ac83-4b89-9158-8812c0a2db6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 18/30 [03:13<02:06, 10.52s/it]"
     ]
    }
   ],
   "source": [
    "epochs = 30 + epoch\n",
    "for epoch in tqdm(range(epoch, epochs)):\n",
    "    poisevae.utils.train(vae, train_loader, optimizer, epoch, writer)\n",
    "    labels, latent_info = poisevae.utils.test(vae, test_loader, epoch, writer, \n",
    "                                              record_idx=(2, 3), return_latents=True)\n",
    "    if (epoch+1) % 10 == 0 and epoch > 0:\n",
    "        poisevae.utils.save_checkpoint(vae, optimizer, os.path.join(PATH, 'training_%d.pt' % (epoch+1)), epoch+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1e5e8a-d52e-484f-ac4f-40a0912060af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5485119-865e-4f47-8582-c537aec18bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# poisevae.utils.save_latent_info(latent_info, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31ffee9-0b2c-4644-b4f2-abb009517f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vae, optimizer, epoch = poisevae.utils.load_checkpoint(vae, optimizer, sorted(glob.glob(PATH + 'train*.pt'))[-1])\n",
    "# epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26711b10-747c-4df5-a4a5-9ba9ec35039c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader):\n",
    "        results = vae([data[0].to(device, dtype=torch.float32), data[1].to(device, dtype=torch.float32)])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515f0943-8582-492f-85bb-b7d9058d348c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rec = results['x_rec']\n",
    "if isinstance(x_rec[0], torch.distributions.Distribution):\n",
    "    x_rec = [x_rec[0].loc, x_rec[1].loc]\n",
    "    \n",
    "x_rec[1].shape, data[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588254ab-835f-4164-a6b1-2850d95a3c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = min(len(x_rec[0]), 20)\n",
    "fig, ax = plt.subplots(nrows=2, ncols=ncols, figsize=(15, 1.5))\n",
    "for i, aux in enumerate(zip(data[0], x_rec[0])):\n",
    "    if i >= ncols:\n",
    "        break\n",
    "    for j, im in enumerate(aux):\n",
    "        ax[j, i].imshow(im.cpu().numpy().reshape(28, 28), cmap='gray')\n",
    "        ax[j, i].set_xticks([])\n",
    "        ax[j, i].set_yticks([])\n",
    "ax[1, 0].set_ylabel('Rec', fontsize=24)\n",
    "fig.tight_layout(pad=0)\n",
    "# fig.savefig(PATH + 'MNISTRec.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53febad-31c1-4bd6-8092-2978e948bfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = min(len(x_rec[0]), 20)\n",
    "nrows = 2 * int(np.floor(len(x_rec[0]) / 20))\n",
    "fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(15, 1.5*nrows/2))\n",
    "for i, aux in enumerate(zip(data[0], x_rec[0])):\n",
    "    if i >= nrows / 2 * 20:\n",
    "        break\n",
    "    for j, im in enumerate(aux):\n",
    "        ax[j+i//20*2, i%20].imshow(im.cpu().numpy().reshape(28, 28), cmap='gray')\n",
    "        ax[j+i//20*2, i%20].set_xticks([])\n",
    "        ax[j+i//20*2, i%20].set_yticks([])\n",
    "    ax[1+i//20*2, 0].set_ylabel('Rec', fontsize=24)\n",
    "fig.tight_layout(pad=0)\n",
    "# fig.savefig(PATH + 'MNISTRecExtra.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b1b742-9a70-4d16-a07f-20ad3dae2e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = min(len(x_rec[1]), 20)\n",
    "fig, ax = plt.subplots(nrows=2, ncols=ncols, figsize=(15, 1.5))\n",
    "for i, aux in enumerate(zip(data[1], x_rec[1])):\n",
    "    if i >= ncols:\n",
    "        break\n",
    "    for j, im in enumerate(aux):\n",
    "        ax[j, i].imshow(im.cpu().numpy().transpose(1, 2, 0), cmap='gray')\n",
    "        ax[j, i].set_xticks([])\n",
    "        ax[j, i].set_yticks([])\n",
    "ax[1, 0].set_ylabel('Rec', fontsize=24)\n",
    "fig.tight_layout(pad=0)\n",
    "# fig.savefig(PATH + 'SVHNRec.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451d0084-7710-4043-b012-696c82fd3677",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = min(len(x_rec[1]), 20)\n",
    "nrows = 2 * int(np.floor(len(x_rec[1]) / 20))\n",
    "fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(15, 1.5*nrows/2))\n",
    "for i, aux in enumerate(zip(data[1], x_rec[1])):\n",
    "    if i >= nrows / 2 * 20:\n",
    "        break\n",
    "    for j, im in enumerate(aux):\n",
    "        ax[j+i//20*2, i%20].imshow(im.cpu().numpy().transpose(1, 2, 0), cmap='gray')\n",
    "        ax[j+i//20*2, i%20].set_xticks([])\n",
    "        ax[j+i//20*2, i%20].set_yticks([])\n",
    "    ax[1+i//20*2, 0].set_ylabel('Rec', fontsize=24)\n",
    "fig.tight_layout(pad=0)\n",
    "# fig.savefig(PATH + 'SVHNRecExtra.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6b06c1-dc08-46ae-876e-7cd273e1ab77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
