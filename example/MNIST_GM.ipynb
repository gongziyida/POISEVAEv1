{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b923f86-60f5-469b-8181-8306ee5422db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F  # activation function\n",
    "from torch.distributions import Laplace, Normal\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import poisevae\n",
    "from poisevae.datasets import MNIST_GM\n",
    "\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 20\n",
    "plt.rcParams['font.weight'] = 'normal'\n",
    "plt.rcParams['mathtext.fontset'] = 'cm'\n",
    "plt.rcParams['text.usetex'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "200baa32-4b85-4438-b679-6cfd7b163970",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_PATH = os.path.expanduser('~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d096cdcb-06a5-4eac-987b-244d916546a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncMNIST(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(EncMNIST, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.dim_MNIST = 28 * 28\n",
    "\n",
    "        self.enc1 = nn.Linear(self.dim_MNIST, 400)\n",
    "        self.enc_mu = nn.Linear(400, latent_dim)\n",
    "        self.enc_var = nn.Linear(400, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.enc1(x))\n",
    "        mu = self.enc_mu(x)\n",
    "        log_var = self.enc_var(x)\n",
    "        return mu, log_var\n",
    "\n",
    "class DecMNIST(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(DecMNIST, self).__init__()  \n",
    "        self.latent_dim = latent_dim\n",
    "        self.dim_MNIST   = 28 * 28\n",
    "        \n",
    "        self.dec = nn.Sequential(nn.Linear(self.latent_dim, 400), \n",
    "                                 nn.ReLU(inplace=True), \n",
    "                                 nn.Linear(400, self.dim_MNIST), \n",
    "                                 nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, z):\n",
    "        return self.dec(z), torch.tensor(0.75).to(z.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edfe8033-019e-47bb-b728-ffe230d14a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncGM(nn.Module):\n",
    "    def __init__(self, data_dim, emb_dim, latent_dim):\n",
    "        super(EncGM, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.data_dim = data_dim\n",
    "        if latent_dim > data_dim:\n",
    "            raise ValueError('latent_dim > data_dim')\n",
    "\n",
    "        self.enc = nn.Sequential(nn.Linear(data_dim, emb_dim),\n",
    "                                 nn.LeakyReLU(inplace=True))\n",
    "        self.enc_mu = nn.Linear(emb_dim, latent_dim)\n",
    "        self.enc_var = nn.Linear(emb_dim, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.enc(x)\n",
    "        mu = self.enc_mu(x)\n",
    "        log_var = self.enc_var(x)\n",
    "        return mu, log_var\n",
    "\n",
    "class DecGM(nn.Module):\n",
    "    def __init__(self, data_dim, emb_dim, latent_dim):\n",
    "        super(DecGM, self).__init__()  \n",
    "        self.latent_dim = latent_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.data_dim = data_dim\n",
    "        if latent_dim > data_dim:\n",
    "            raise ValueError('latent_dim > data_dim')\n",
    "            \n",
    "        self.dec = nn.Sequential(nn.Linear(latent_dim, emb_dim), \n",
    "                                 nn.LeakyReLU(inplace=True),\n",
    "                                 nn.Linear(emb_dim, data_dim))\n",
    "        \n",
    "    def forward(self, z):\n",
    "        return self.dec(z), torch.tensor(0.75).to(z.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cba9b1ec-5083-4a19-affa-e0720b60d3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc4383bd-e443-49a6-afe9-1ffcc2a8f016",
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_PATH = os.path.join(HOME_PATH, 'Datasets/MNIST/MNIST/processed/%s.pt')\n",
    "\n",
    "joint_dataset_train = MNIST_GM(mnist_pt_path=MNIST_PATH % 'train', data_augment=1)\n",
    "joint_dataset_test = MNIST_GM(mnist_pt_path=MNIST_PATH % 'test', data_augment=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e601a8c-e46f-4cf0-9985-f2431788ec5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188, 31)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 256\n",
    "train_loader = torch.utils.data.DataLoader(joint_dataset_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(joint_dataset_test, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a68120dc-2f9e-49b1-8dfc-579032c915b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat1, lat2 = 20, 2\n",
    "emb_dim = 8\n",
    "enc_mnist = EncMNIST(lat1).to(device)\n",
    "dec_mnist = DecMNIST(lat1).to(device)\n",
    "enc_gm = EncGM(2, emb_dim, lat2).to(device)\n",
    "dec_gm = DecGM(2, emb_dim, lat2).to(device)\n",
    "\n",
    "def MSELoss(input, target):\n",
    "    loss = nn.functional.mse_loss(input, target, reduction='sum') #/ input.shape[0]\n",
    "    return loss\n",
    "    \n",
    "def MAELoss(input, target):\n",
    "    loss = nn.functional.l1_loss(input, target, reduction='sum') #/ input.shape[0]\n",
    "    return loss\n",
    "\n",
    "vae = poisevae.POISEVAE([enc_mnist, enc_gm], [dec_mnist, dec_gm], likelihoods=[Laplace, Normal], \n",
    "                        latent_dims=[lat1, lat2], reduction='mean', batch_size=batch_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ccb1dfb-d583-4edb-b017-ae9c646567af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in vae.named_parameters():\n",
    "#     print(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "292dc208-4258-4108-ae4d-80d954ab45dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(vae.parameters(), lr=1e-3, amsgrad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12663d4c-8f82-4b21-bed4-67044e7ea7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = os.path.join(HOME_PATH, 'Datasets/MNIST_GM_train_results/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c8f75ff-8b35-4e7a-b25d-324a43c1040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "# try:\n",
    "#     vae, optimizer, epoch = load_checkpoint(vae, optimizer, sorted(glob.glob(PATH + 'train*.pt'))[-1])\n",
    "# except:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee965133-67c9-4162-8494-30205c86be54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "writer = SummaryWriter('runs/MNIST_GM/' + datetime.now().strftime('%y%m%d%H%M'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22ac5d3-8480-4da8-b559-9e7801004605",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|███████████████████▎                       | 18/40 [01:06<01:17,  3.51s/it]"
     ]
    }
   ],
   "source": [
    "epochs = 40 + epoch\n",
    "for epoch in tqdm(range(epoch, epochs)):\n",
    "    poisevae.utils.train(vae, train_loader, optimizer, epoch, writer)\n",
    "    labels, latent_info = poisevae.utils.test(vae, test_loader, epoch, writer, \n",
    "                                              record_idx=(2, 3), return_latents=True)\n",
    "    if (epoch+1) % 10 == 0 and epoch > 0:\n",
    "        poisevae.utils.save_checkpoint(vae, optimizer, PATH + 'training_%d.pt' % (epoch+1), epoch+1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa66afa-6b8c-44cf-b9fb-3d04c6200022",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ea1deb-19d1-49c9-b6ce-37b5594a2919",
   "metadata": {},
   "outputs": [],
   "source": [
    "poisevae.utils.save_latent_info(latent_info, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfa7c0f-50ef-4f93-a07e-abd02ec60b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vae, optimizer, epoch = poisevae.utils.load_checkpoint(vae, optimizer, sorted(glob.glob(PATH + 'train*.pt'))[-1])\n",
    "# epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26711b10-747c-4df5-a4a5-9ba9ec35039c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader):\n",
    "        results = vae([data[0].to(device, dtype=torch.float32), data[1].to(device, dtype=torch.float32)])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa049d4-aced-4b84-a2b8-28b21b3d0f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rec = results['x_rec']\n",
    "if isinstance(x_rec[0], torch.distributions.Distribution):\n",
    "    x_rec = [x_rec[0].loc, x_rec[1].loc]\n",
    "    \n",
    "x_rec[1].shape, data[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29b620c-e362-4afc-82e8-5ae452805d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = min(len(x_rec[0]), 20)\n",
    "fig, ax = plt.subplots(nrows=2, ncols=ncols, figsize=(15, 1.5))\n",
    "for i, aux in enumerate(zip(data[0], x_rec[0])):\n",
    "    if i >= ncols:\n",
    "        break\n",
    "    for j, im in enumerate(aux):\n",
    "        ax[j, i].imshow(im.cpu().numpy().reshape(28, 28), cmap='gray')\n",
    "        ax[j, i].set_xticks([])\n",
    "        ax[j, i].set_yticks([])\n",
    "ax[1, 0].set_ylabel('Rec', fontsize=24)\n",
    "fig.tight_layout(pad=0)\n",
    "# fig.savefig(PATH + 'MNISTRec.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1fd32b-c6e7-49b5-be5e-37f0fb39cd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = min(len(x_rec[0]), 20)\n",
    "nrows = 2 * int(np.floor(len(x_rec[0]) / 20))\n",
    "fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(15, 1.5*nrows/2))\n",
    "for i, aux in enumerate(zip(data[0], x_rec[0])):\n",
    "    if i >= nrows / 2 * 20:\n",
    "        break\n",
    "    for j, im in enumerate(aux):\n",
    "        ax[j+i//20*2, i%20].imshow(im.cpu().numpy().reshape(28, 28), cmap='gray')\n",
    "        ax[j+i//20*2, i%20].set_xticks([])\n",
    "        ax[j+i//20*2, i%20].set_yticks([])\n",
    "    ax[1+i//20*2, 0].set_ylabel('Rec', fontsize=24)\n",
    "fig.tight_layout(pad=0)\n",
    "# fig.savefig(PATH + 'MNISTRecExtra.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c966b365-e360-46b9-947e-7ef4d201394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(5, 5))\n",
    "for i in range(8):\n",
    "    ax.scatter(*x_rec[1][data[-1]==i+1].detach().cpu().numpy().T, c='C%d'%i, s=10, zorder=2)\n",
    "    ax.scatter(*data[1][data[-1]==i+1].detach().cpu().numpy().T, c='C%d'%i, marker='x', zorder=3)\n",
    "ax.set_yticks([-2.5, 0, 2.5])\n",
    "ax.plot([], [], marker='.', c='k', alpha=1, label='Rec.', linewidth=0)\n",
    "ax.plot([], [], marker='x', c='k', alpha=1, label='Truth', linewidth=0)\n",
    "fig.legend(fontsize='small', loc=(0.71, 0.11), ncol=1, handletextpad=0, labelspacing=0)\n",
    "fig.tight_layout()\n",
    "# fig.savefig(PATH + 'GMRec.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bd2a1c-7444-4277-8f47-059e41a47e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
